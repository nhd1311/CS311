CHROMA_HOST=chroma
CHROMA_PORT=8000
EMBED_MODEL=sentence-transformers/all-MiniLM-L6-v2
IMAGE_MODEL=ViT-B-32
IMAGE_MODEL_PRETRAINED=openai
# Hugging Face Inference Providers (khuyến nghị): dùng OpenAI-compatible endpoint qua router.
# Lưu ý: cần token HF trong LLM_API_KEY (quyền “Make calls to Inference Providers”).
LLM_BASE_URL=https://router.huggingface.co/v1
LLM_API_KEY=hf_your_token_here
LLM_MODEL=meta-llama/Llama-3.1-8B-Instruct
LLM_DEBUG=0

# Force using LLM to generate `answer` even when products are available.
# Default is 0 (deterministic answer from products to avoid hallucination).
USE_LLM_ANSWER=0

# Chat behavior toggles
ASK_FOLLOWUPS=0
STRICT_EXACT_LOOKUP=0

# RAG relevance gating (Chroma distances: lower is better)
RAG_MAX_DISTANCE=1.0
RAG_MIN_TOKEN_OVERLAP=0.12
RAG_MIN_DISTINCTIVE_MATCHES=1
