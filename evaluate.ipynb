{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e87d41e",
   "metadata": {},
   "source": [
    "# Đánh giá hệ thống Chatbot (Fashion RAG)\n",
    "\n",
    "Notebook này đánh giá chatbot của bạn theo 5 nhóm chính:\n",
    "\n",
    "1) **Truy hồi/RAG** (khi có nhãn *gold*): Hit@K, Recall@K, MRR, nDCG@K.\n",
    "2) **Độ đúng tác vụ (không cần câu trả lời tham chiếu)**: mức **tuân thủ ràng buộc** (budget, màu, usage/occasion, gender, articleType).\n",
    "3) **Tính trung thực/groundedness của câu trả lời**: câu trả lời có “bịa” ngoài danh sách `products` trả về hay không (heuristic).\n",
    "4) **An toàn** (heuristic): phát hiện rò rỉ PII (email/phone/CC) và nội dung nhạy cảm theo regex.\n",
    "5) **Hiệu năng**: latency p50/p90/p95, tỉ lệ lỗi, tỉ lệ kết quả rỗng.\n",
    "\n",
    "> Lưu ý: API hiện **English-only** (trong `app/main.py`). Notebook có kiểm thử hành vi từ chối với query tiếng Việt.\n",
    "\n",
    "---\n",
    "\n",
    "## Các độ đo gợi ý (tóm tắt)\n",
    "\n",
    "### Truy hồi / RAG\n",
    "- **Hit@K**: có ít nhất 1 tài liệu đúng trong top-K.\n",
    "- **Recall@K**: $\\frac{|\\text{relevant} \\cap \\text{topK}|}{|\\text{relevant}|}$.\n",
    "- **MRR**: $\\text{MRR} = \\frac{1}{N}\\sum_i \\frac{1}{\\text{rank}_i}$ (rank của kết quả đúng đầu tiên).\n",
    "- **nDCG@K**: đo chất lượng thứ hạng; với relevance nhị phân, DCG@K = $\\sum_{j=1..K} \\frac{rel_j}{\\log_2(j+1)}$.\n",
    "\n",
    "### Tác vụ / Mức tuân thủ ràng buộc\n",
    "- **Budget adherence**: mọi item trả về có price nằm trong [$min$, $max$] (nếu có price).\n",
    "- **Color/Usage/Gender/Type adherence**: tỉ lệ item khớp ràng buộc.\n",
    "\n",
    "### Hiệu năng\n",
    "- **Latency p50/p95**, **Tỉ lệ lỗi**, **Tỉ lệ không có sản phẩm**.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3638da85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifacts: D:\\Study\\CS311\\CS311\\artifacts\n",
      "Outputs: D:\\Study\\CS311\\CS311\\outputs\n"
     ]
    }
   ],
   "source": [
    "# 1) Cài đặt & import thư viện\n",
    "# Notebook ưu tiên chạy được với requirements.txt hiện có.\n",
    "# Một số thư viện (tqdm, matplotlib, seaborn, rouge_score, sacrebleu, bert_score, tiktoken, jsonschema)\n",
    "# sẽ được import theo kiểu optional.\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import hashlib\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Import tuỳ chọn\n",
    "try:\n",
    "    from tqdm.auto import tqdm\n",
    "except Exception:\n",
    "    tqdm = None\n",
    "\n",
    "try:\n",
    "    import numpy as np\n",
    "except Exception:\n",
    "    np = None\n",
    "\n",
    "# Vẽ biểu đồ (tuỳ chọn)\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "except Exception:\n",
    "    plt = None\n",
    "\n",
    "ARTIFACTS_DIR = Path(\"artifacts\")\n",
    "OUTPUTS_DIR = Path(\"outputs\")\n",
    "ARTIFACTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUTPUTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Artifacts:\", ARTIFACTS_DIR.resolve())\n",
    "print(\"Outputs:\", OUTPUTS_DIR.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a5497e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"api_base\": \"http://127.0.0.1:8081\",\n",
      "  \"timeout_s\": 30.0,\n",
      "  \"max_retries\": 2,\n",
      "  \"top_k_default\": 5,\n",
      "  \"timestamp\": \"2026-01-14 09:19:58\"\n",
      "}\n",
      "/health {'status': 200, 'latency_ms': 6.08, 'data': {'status': 'ok'}, 'err': None}\n"
     ]
    }
   ],
   "source": [
    "# 2) Khai báo cấu hình thí nghiệm\n",
    "\n",
    "API_BASE = os.getenv(\"API_BASE\", \"http://127.0.0.1:8081\").rstrip(\"/\")\n",
    "TIMEOUT_S = float(os.getenv(\"EVAL_TIMEOUT_S\", \"30\"))\n",
    "MAX_RETRIES = int(os.getenv(\"EVAL_MAX_RETRIES\", \"2\"))\n",
    "TOP_K_DEFAULT = int(os.getenv(\"EVAL_TOP_K\", \"5\"))\n",
    "\n",
    "CONFIG = {\n",
    "    \"api_base\": API_BASE,\n",
    "    \"timeout_s\": TIMEOUT_S,\n",
    "    \"max_retries\": MAX_RETRIES,\n",
    "    \"top_k_default\": TOP_K_DEFAULT,\n",
    "    \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "}\n",
    "\n",
    "(ARTIFACTS_DIR / \"eval_config.json\").write_text(json.dumps(CONFIG, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "print(json.dumps(CONFIG, ensure_ascii=False, indent=2))\n",
    "\n",
    "\n",
    "def _request_json(method: str, url: str, payload: Optional[dict] = None) -> Tuple[int, dict, float, Optional[str]]:\n",
    "    \"\"\"Hàm trợ giúp HTTP có retry.\n",
    "\n",
    "    Trả về: (status_code, json_or_error, latency_ms, error_text)\n",
    "    \"\"\"\n",
    "    last_err = None\n",
    "    for attempt in range(MAX_RETRIES + 1):\n",
    "        t0 = time.perf_counter()\n",
    "        try:\n",
    "            resp = requests.request(\n",
    "                method=method,\n",
    "                url=url,\n",
    "                json=payload,\n",
    "                timeout=TIMEOUT_S,\n",
    "            )\n",
    "            latency_ms = (time.perf_counter() - t0) * 1000\n",
    "            try:\n",
    "                data = resp.json()\n",
    "            except Exception:\n",
    "                data = {\"_raw\": resp.text}\n",
    "            if 200 <= resp.status_code < 300:\n",
    "                return resp.status_code, data, latency_ms, None\n",
    "            last_err = f\"HTTP {resp.status_code}: {data}\"\n",
    "            # Retry khi gặp lỗi 5xx\n",
    "            if resp.status_code >= 500 and attempt < MAX_RETRIES:\n",
    "                time.sleep(0.5 * (attempt + 1))\n",
    "                continue\n",
    "            return resp.status_code, data, latency_ms, last_err\n",
    "        except Exception as e:\n",
    "            latency_ms = (time.perf_counter() - t0) * 1000\n",
    "            last_err = f\"{type(e).__name__}: {e}\"\n",
    "            if attempt < MAX_RETRIES:\n",
    "                time.sleep(0.5 * (attempt + 1))\n",
    "                continue\n",
    "            return 0, {}, latency_ms, last_err\n",
    "\n",
    "\n",
    "def healthcheck() -> bool:\n",
    "    status, data, ms, err = _request_json(\"GET\", f\"{API_BASE}/health\")\n",
    "    print(\"/health\", {\"status\": status, \"latency_ms\": round(ms, 2), \"data\": data, \"err\": err})\n",
    "    return status == 200\n",
    "\n",
    "\n",
    "_healthy = healthcheck()\n",
    "if not _healthy:\n",
    "    print(\n",
    "        \"\\n[HINT] API chưa chạy hoặc sai API_BASE.\\n\"\n",
    "        \"- Nếu chạy bằng docker compose: mở http://127.0.0.1:8081/docs\\n\"\n",
    "        \"- Nếu chạy local uvicorn: kiểm tra port và biến API_BASE\\n\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e57e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 test cases\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>query</th>\n",
       "      <th>expected_ids</th>\n",
       "      <th>expected_constraints</th>\n",
       "      <th>should_reject</th>\n",
       "      <th>top_k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>basic_men_shoes_budget</td>\n",
       "      <td>men black sneakers under $80</td>\n",
       "      <td>None</td>\n",
       "      <td>{'gender': 'Men', 'color': 'Black', 'max_price...</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>formal_office</td>\n",
       "      <td>women formal office outfit under $100</td>\n",
       "      <td>None</td>\n",
       "      <td>{'usage': 'Formal', 'max_price': 100}</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>color_strict</td>\n",
       "      <td>women red dress</td>\n",
       "      <td>None</td>\n",
       "      <td>{'color': 'Red'}</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>type_tshirts</td>\n",
       "      <td>men white t-shirt</td>\n",
       "      <td>None</td>\n",
       "      <td>{'articleType': 'Tshirts', 'color': 'White', '...</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>reject_vietnamese</td>\n",
       "      <td>Tôi muốn mua áo sơ mi trắng đi làm dưới 40 đô</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     name                                          query  \\\n",
       "0  basic_men_shoes_budget                   men black sneakers under $80   \n",
       "1           formal_office          women formal office outfit under $100   \n",
       "2            color_strict                                women red dress   \n",
       "3            type_tshirts                              men white t-shirt   \n",
       "4       reject_vietnamese  Tôi muốn mua áo sơ mi trắng đi làm dưới 40 đô   \n",
       "\n",
       "  expected_ids                               expected_constraints  \\\n",
       "0         None  {'gender': 'Men', 'color': 'Black', 'max_price...   \n",
       "1         None              {'usage': 'Formal', 'max_price': 100}   \n",
       "2         None                                   {'color': 'Red'}   \n",
       "3         None  {'articleType': 'Tshirts', 'color': 'White', '...   \n",
       "4         None                                               None   \n",
       "\n",
       "   should_reject  top_k  \n",
       "0          False      5  \n",
       "1          False      5  \n",
       "2          False      5  \n",
       "3          False      5  \n",
       "4           True      5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3) Chuẩn hoá schema dữ liệu test & loader (đơn giản)\n",
    "\n",
    "# Trong project này, endpoint /chat nhận:\n",
    "# { query: str, top_k: int, filters?: dict, messages?: [{role,content}], max_tokens?: int, temperature?: float }\n",
    "# Trả về: { answer: str, products: [...], sources: [...] }\n",
    "\n",
    "@dataclass\n",
    "class TestCase:\n",
    "    name: str\n",
    "    query: str\n",
    "    expected_ids: Optional[List[str]] = None  # nếu bạn có nhãn product id đúng\n",
    "    expected_constraints: Optional[Dict[str, Any]] = None\n",
    "    should_reject: bool = False\n",
    "    top_k: int = TOP_K_DEFAULT\n",
    "\n",
    "\n",
    "def default_testset() -> List[TestCase]:\n",
    "    # LƯU Ý: API chỉ hỗ trợ tiếng Anh, nên query nên là tiếng Anh.\n",
    "    # expected_ids: bạn có thể điền sau (sau khi ingest xong) để tính retrieval metrics.\n",
    "    return [\n",
    "        TestCase(\n",
    "            name=\"basic_men_shoes_budget\",\n",
    "            query=\"men black sneakers under $80\",\n",
    "            expected_constraints={\"gender\": \"Men\", \"color\": \"Black\", \"max_price\": 80},\n",
    "        ),\n",
    "        TestCase(\n",
    "            name=\"formal_office\",\n",
    "            query=\"women formal office outfit under $100\",\n",
    "            expected_constraints={\"usage\": \"Formal\", \"max_price\": 100},\n",
    "        ),\n",
    "        TestCase(\n",
    "            name=\"color_strict\",\n",
    "            query=\"women red dress\",\n",
    "            expected_constraints={\"color\": \"Red\"},\n",
    "        ),\n",
    "        TestCase(\n",
    "            name=\"type_tshirts\",\n",
    "            query=\"men white t-shirt\",\n",
    "            expected_constraints={\"articleType\": \"Tshirts\", \"color\": \"White\", \"gender\": \"Men\"},\n",
    "        ),\n",
    "        # Kiểm thử English-only: tiếng Việt có dấu sẽ bị từ chối\n",
    "        TestCase(\n",
    "            name=\"reject_vietnamese\",\n",
    "            query=\"Tôi muốn mua áo sơ mi trắng đi làm dưới 40 đô\",\n",
    "            should_reject=True,\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "\n",
    "TESTSET = default_testset()\n",
    "print(f\"Loaded {len(TESTSET)} test cases\")\n",
    "pd.DataFrame([t.__dict__ for t in TESTSET])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f4658e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>query</th>\n",
       "      <th>should_reject</th>\n",
       "      <th>expected_ids</th>\n",
       "      <th>expected_constraints</th>\n",
       "      <th>status</th>\n",
       "      <th>latency_ms</th>\n",
       "      <th>error</th>\n",
       "      <th>cached</th>\n",
       "      <th>answer</th>\n",
       "      <th>products</th>\n",
       "      <th>sources</th>\n",
       "      <th>n_products</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>basic_men_shoes_budget</td>\n",
       "      <td>men black sneakers under $80</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>{'gender': 'Men', 'color': 'Black', 'max_price...</td>\n",
       "      <td>200</td>\n",
       "      <td>531.8409</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>Quick summary: Here are the closest matches fo...</td>\n",
       "      <td>[{'id': '24626', 'name': 'Converse Men Black R...</td>\n",
       "      <td>[{'id': '24626', 'text': 'Converse Men Black R...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>formal_office</td>\n",
       "      <td>women formal office outfit under $100</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>{'usage': 'Formal', 'max_price': 100}</td>\n",
       "      <td>200</td>\n",
       "      <td>1042.7743</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>Quick summary: Here are the closest matches fo...</td>\n",
       "      <td>[{'id': '57116', 'name': 'Elle Women White Sem...</td>\n",
       "      <td>[{'id': '57116', 'text': 'Elle Women White Sem...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>color_strict</td>\n",
       "      <td>women red dress</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>{'color': 'Red'}</td>\n",
       "      <td>200</td>\n",
       "      <td>43.0992</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>Quick summary: Here are the closest matches fo...</td>\n",
       "      <td>[{'id': '45777', 'name': 'Remanika Women Red D...</td>\n",
       "      <td>[{'id': '45777', 'text': 'Remanika Women Red D...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>type_tshirts</td>\n",
       "      <td>men white t-shirt</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>{'articleType': 'Tshirts', 'color': 'White', '...</td>\n",
       "      <td>200</td>\n",
       "      <td>39.2038</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>Quick summary: Here are the closest matches fo...</td>\n",
       "      <td>[{'id': '2853', 'name': 'Mr.Men Printed White ...</td>\n",
       "      <td>[{'id': '2853', 'text': 'Mr.Men Printed White ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>reject_vietnamese</td>\n",
       "      <td>Tôi muốn mua áo sơ mi trắng đi làm dưới 40 đô</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>3.6427</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>English only: please rephrase your request in ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     name                                          query  \\\n",
       "0  basic_men_shoes_budget                   men black sneakers under $80   \n",
       "1           formal_office          women formal office outfit under $100   \n",
       "2            color_strict                                women red dress   \n",
       "3            type_tshirts                              men white t-shirt   \n",
       "4       reject_vietnamese  Tôi muốn mua áo sơ mi trắng đi làm dưới 40 đô   \n",
       "\n",
       "   should_reject expected_ids  \\\n",
       "0          False         None   \n",
       "1          False         None   \n",
       "2          False         None   \n",
       "3          False         None   \n",
       "4           True         None   \n",
       "\n",
       "                                expected_constraints  status  latency_ms  \\\n",
       "0  {'gender': 'Men', 'color': 'Black', 'max_price...     200    531.8409   \n",
       "1              {'usage': 'Formal', 'max_price': 100}     200   1042.7743   \n",
       "2                                   {'color': 'Red'}     200     43.0992   \n",
       "3  {'articleType': 'Tshirts', 'color': 'White', '...     200     39.2038   \n",
       "4                                               None     200      3.6427   \n",
       "\n",
       "  error  cached                                             answer  \\\n",
       "0  None    True  Quick summary: Here are the closest matches fo...   \n",
       "1  None    True  Quick summary: Here are the closest matches fo...   \n",
       "2  None    True  Quick summary: Here are the closest matches fo...   \n",
       "3  None    True  Quick summary: Here are the closest matches fo...   \n",
       "4  None    True  English only: please rephrase your request in ...   \n",
       "\n",
       "                                            products  \\\n",
       "0  [{'id': '24626', 'name': 'Converse Men Black R...   \n",
       "1  [{'id': '57116', 'name': 'Elle Women White Sem...   \n",
       "2  [{'id': '45777', 'name': 'Remanika Women Red D...   \n",
       "3  [{'id': '2853', 'name': 'Mr.Men Printed White ...   \n",
       "4                                                 []   \n",
       "\n",
       "                                             sources  n_products  \n",
       "0  [{'id': '24626', 'text': 'Converse Men Black R...           5  \n",
       "1  [{'id': '57116', 'text': 'Elle Women White Sem...           4  \n",
       "2  [{'id': '45777', 'text': 'Remanika Women Red D...           5  \n",
       "3  [{'id': '2853', 'text': 'Mr.Men Printed White ...           5  \n",
       "4                                                 []           0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4) Chạy chatbot hàng loạt (batch) + logging\n",
    "\n",
    "CACHE_PATH = ARTIFACTS_DIR / \"eval_cache.json\"\n",
    "try:\n",
    "    _CACHE = json.loads(CACHE_PATH.read_text(encoding=\"utf-8\")) if CACHE_PATH.exists() else {}\n",
    "except Exception:\n",
    "    _CACHE = {}\n",
    "\n",
    "\n",
    "def _hash_payload(payload: dict) -> str:\n",
    "    s = json.dumps(payload, sort_keys=True, ensure_ascii=False)\n",
    "    return hashlib.sha256(s.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "\n",
    "def call_chat(query: str, top_k: int = 5, filters: Optional[dict] = None, messages: Optional[list] = None) -> dict:\n",
    "    payload: Dict[str, Any] = {\n",
    "        \"query\": query,\n",
    "        \"top_k\": int(top_k),\n",
    "    }\n",
    "    if filters:\n",
    "        payload[\"filters\"] = filters\n",
    "    if messages:\n",
    "        payload[\"messages\"] = messages\n",
    "\n",
    "    key = _hash_payload(payload)\n",
    "    if key in _CACHE:\n",
    "        out = dict(_CACHE[key])\n",
    "        out[\"_cached\"] = True\n",
    "        return out\n",
    "\n",
    "    status, data, latency_ms, err = _request_json(\"POST\", f\"{API_BASE}/chat\", payload)\n",
    "    out = {\n",
    "        \"status\": status,\n",
    "        \"latency_ms\": latency_ms,\n",
    "        \"error\": err,\n",
    "        \"response\": data,\n",
    "        \"_cached\": False,\n",
    "    }\n",
    "    _CACHE[key] = out\n",
    "    return out\n",
    "\n",
    "\n",
    "def run_eval(testset: List[TestCase]) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    iterator = tqdm(testset, desc=\"Đang đánh giá\") if tqdm else testset\n",
    "    for tc in iterator:\n",
    "        res = call_chat(tc.query, top_k=tc.top_k)\n",
    "        resp = res.get(\"response\") or {}\n",
    "        products = resp.get(\"products\") or []\n",
    "        sources = resp.get(\"sources\") or []\n",
    "        answer = resp.get(\"answer\")\n",
    "        rows.append(\n",
    "            {\n",
    "                \"name\": tc.name,\n",
    "                \"query\": tc.query,\n",
    "                \"should_reject\": bool(tc.should_reject),\n",
    "                \"expected_ids\": tc.expected_ids,\n",
    "                \"expected_constraints\": tc.expected_constraints,\n",
    "                \"status\": res.get(\"status\"),\n",
    "                \"latency_ms\": float(res.get(\"latency_ms\") or 0.0),\n",
    "                \"error\": res.get(\"error\"),\n",
    "                \"cached\": bool(res.get(\"_cached\")),\n",
    "                \"answer\": answer,\n",
    "                \"products\": products,\n",
    "                \"sources\": sources,\n",
    "                \"n_products\": len(products) if isinstance(products, list) else 0,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    # Lưu cache và kết quả thô\n",
    "    CACHE_PATH.write_text(json.dumps(_CACHE, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "    (ARTIFACTS_DIR / \"predictions.jsonl\").write_text(\n",
    "        \"\\n\".join(json.dumps(r, ensure_ascii=False) for r in rows),\n",
    "        encoding=\"utf-8\",\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "DF = run_eval(TESTSET)\n",
    "DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4832947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"n_cases\": 5,\n",
      "  \"error_rate\": 0.0,\n",
      "  \"empty_products_rate\": 0.2,\n",
      "  \"latency_p50_ms\": 43.099200000142446,\n",
      "  \"latency_p90_ms\": 838.4009399997012,\n",
      "  \"latency_p95_ms\": 940.5876199998601,\n",
      "  \"latency_mean_ms\": 332.11217999923974,\n",
      "  \"english_only_reject_accuracy\": 1.0,\n",
      "  \"constraint_pass_rate\": 0.8,\n",
      "  \"faithfulness_pass_rate\": 0.8\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>status</th>\n",
       "      <th>latency_ms</th>\n",
       "      <th>n_products</th>\n",
       "      <th>rejected_english_only</th>\n",
       "      <th>faith_mentioned_ids</th>\n",
       "      <th>faith_extra_ids_not_in_products</th>\n",
       "      <th>faith_money_mentions</th>\n",
       "      <th>faith_money_matches_products</th>\n",
       "      <th>faith_faithful</th>\n",
       "      <th>...</th>\n",
       "      <th>hit@1</th>\n",
       "      <th>recall@1</th>\n",
       "      <th>ndcg@1</th>\n",
       "      <th>hit@3</th>\n",
       "      <th>recall@3</th>\n",
       "      <th>ndcg@3</th>\n",
       "      <th>hit@5</th>\n",
       "      <th>recall@5</th>\n",
       "      <th>ndcg@5</th>\n",
       "      <th>mrr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>basic_men_shoes_budget</td>\n",
       "      <td>200</td>\n",
       "      <td>531.8409</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>[24626, 3585, 6344, 6652]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[80.0, 45.0, 25.0, 80.0, 61.0]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>formal_office</td>\n",
       "      <td>200</td>\n",
       "      <td>1042.7743</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>[12514, 2880, 32407, 57116]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[100.0, 16.0, 5.0, 16.0, 87.0]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>color_strict</td>\n",
       "      <td>200</td>\n",
       "      <td>43.0992</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>[33199, 43680, 45777, 57057]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[110.0, 150.0, 38.0, 27.0]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>type_tshirts</td>\n",
       "      <td>200</td>\n",
       "      <td>39.2038</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>[23945, 2853, 8271, 8274]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[140.0, 111.0, 103.0, 188.0]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>reject_vietnamese</td>\n",
       "      <td>200</td>\n",
       "      <td>3.6427</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     name  status  latency_ms  n_products  \\\n",
       "0  basic_men_shoes_budget     200    531.8409           5   \n",
       "1           formal_office     200   1042.7743           4   \n",
       "2            color_strict     200     43.0992           5   \n",
       "3            type_tshirts     200     39.2038           5   \n",
       "4       reject_vietnamese     200      3.6427           0   \n",
       "\n",
       "   rejected_english_only           faith_mentioned_ids  \\\n",
       "0                  False     [24626, 3585, 6344, 6652]   \n",
       "1                  False   [12514, 2880, 32407, 57116]   \n",
       "2                  False  [33199, 43680, 45777, 57057]   \n",
       "3                  False     [23945, 2853, 8271, 8274]   \n",
       "4                   True                            []   \n",
       "\n",
       "  faith_extra_ids_not_in_products            faith_money_mentions  \\\n",
       "0                              []  [80.0, 45.0, 25.0, 80.0, 61.0]   \n",
       "1                              []  [100.0, 16.0, 5.0, 16.0, 87.0]   \n",
       "2                              []      [110.0, 150.0, 38.0, 27.0]   \n",
       "3                              []    [140.0, 111.0, 103.0, 188.0]   \n",
       "4                              []                              []   \n",
       "\n",
       "   faith_money_matches_products  faith_faithful  ...  hit@1 recall@1 ndcg@1  \\\n",
       "0                          True            True  ...    NaN      NaN    NaN   \n",
       "1                         False           False  ...    NaN      NaN    NaN   \n",
       "2                          True            True  ...    NaN      NaN    NaN   \n",
       "3                          True            True  ...    NaN      NaN    NaN   \n",
       "4                          True            True  ...    NaN      NaN    NaN   \n",
       "\n",
       "  hit@3 recall@3 ndcg@3  hit@5  recall@5  ndcg@5  mrr  \n",
       "0   NaN      NaN    NaN    NaN       NaN     NaN  NaN  \n",
       "1   NaN      NaN    NaN    NaN       NaN     NaN  NaN  \n",
       "2   NaN      NaN    NaN    NaN       NaN     NaN  NaN  \n",
       "3   NaN      NaN    NaN    NaN       NaN     NaN  NaN  \n",
       "4   NaN      NaN    NaN    NaN       NaN     NaN  NaN  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5) Metrics: retrieval + constraint adherence + English-only + hiệu năng\n",
    "\n",
    "def _safe_float(x: Any) -> Optional[float]:\n",
    "    try:\n",
    "        if x is None:\n",
    "            return None\n",
    "        return float(x)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def _normalize_str(x: Any) -> str:\n",
    "    return (\"\" if x is None else str(x)).strip()\n",
    "\n",
    "\n",
    "def _normalize_color(x: Any) -> str:\n",
    "    s = _normalize_str(x).lower()\n",
    "    s = re.sub(r\"[^a-z]+\", \"\", s)\n",
    "    if s == \"grey\":\n",
    "        return \"gray\"\n",
    "    return s\n",
    "\n",
    "\n",
    "def _normalize_article_type(x: Any) -> str:\n",
    "    s = _normalize_str(x).lower()\n",
    "    s = re.sub(r\"[^a-z0-9]+\", \"\", s)\n",
    "    return s\n",
    "\n",
    "\n",
    "def _extract_prices(products: list) -> List[float]:\n",
    "    out = []\n",
    "    for p in products or []:\n",
    "        if not isinstance(p, dict):\n",
    "            continue\n",
    "        v = _safe_float(p.get(\"price\"))\n",
    "        if v is None:\n",
    "            continue\n",
    "        if v >= 0:\n",
    "            out.append(v)\n",
    "    return out\n",
    "\n",
    "\n",
    "def _ids_from_products(products: list) -> List[str]:\n",
    "    out: List[str] = []\n",
    "    for p in products or []:\n",
    "        if isinstance(p, dict) and p.get(\"id\") is not None:\n",
    "            out.append(str(p.get(\"id\")))\n",
    "    return out\n",
    "\n",
    "\n",
    "def _ids_from_sources(sources: list) -> List[str]:\n",
    "    out: List[str] = []\n",
    "    for s in sources or []:\n",
    "        if isinstance(s, dict) and s.get(\"id\") is not None:\n",
    "            out.append(str(s.get(\"id\")))\n",
    "    return out\n",
    "\n",
    "\n",
    "def hit_at_k(pred_ids: List[str], gold_ids: List[str], k: int) -> float:\n",
    "    if not gold_ids:\n",
    "        return float(\"nan\")\n",
    "    topk = pred_ids[:k]\n",
    "    return 1.0 if any(pid in set(gold_ids) for pid in topk) else 0.0\n",
    "\n",
    "\n",
    "def recall_at_k(pred_ids: List[str], gold_ids: List[str], k: int) -> float:\n",
    "    if not gold_ids:\n",
    "        return float(\"nan\")\n",
    "    topk = pred_ids[:k]\n",
    "    g = set(gold_ids)\n",
    "    return len([pid for pid in topk if pid in g]) / max(1, len(g))\n",
    "\n",
    "\n",
    "def mrr(pred_ids: List[str], gold_ids: List[str]) -> float:\n",
    "    if not gold_ids:\n",
    "        return float(\"nan\")\n",
    "    g = set(gold_ids)\n",
    "    for i, pid in enumerate(pred_ids, start=1):\n",
    "        if pid in g:\n",
    "            return 1.0 / i\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def ndcg_at_k(pred_ids: List[str], gold_ids: List[str], k: int) -> float:\n",
    "    if not gold_ids:\n",
    "        return float(\"nan\")\n",
    "    g = set(gold_ids)\n",
    "\n",
    "    def dcg(ids: List[str]) -> float:\n",
    "        s = 0.0\n",
    "        for j, pid in enumerate(ids[:k], start=1):\n",
    "            rel = 1.0 if pid in g else 0.0\n",
    "            s += rel / math.log2(j + 1)\n",
    "        return s\n",
    "\n",
    "    ideal = [pid for pid in gold_ids][:k]\n",
    "    # Nếu số nhãn đúng (gold) nhiều hơn k, DCG lý tưởng sẽ là k phần tử đúng.\n",
    "    if len(ideal) < k:\n",
    "        ideal = ideal + [\"__non__\"] * (k - len(ideal))\n",
    "    denom = dcg(ideal)\n",
    "    if denom <= 0:\n",
    "        return 0.0\n",
    "    return dcg(pred_ids) / denom\n",
    "\n",
    "\n",
    "def english_only_rejected(answer: str, products: list, response_obj: dict) -> bool:\n",
    "    # /chat trả về chuỗi answer; còn /query (nếu có) thường trả về trường error.\n",
    "    a = (answer or \"\").lower()\n",
    "    if \"english only\" in a:\n",
    "        return True\n",
    "    if isinstance(response_obj, dict) and \"error\" in response_obj:\n",
    "        if \"english\" in str(response_obj.get(\"error\") or \"\").lower():\n",
    "            return True\n",
    "    # Heuristic: từ chối nếu không có products và thông điệp gợi ý dùng tiếng Anh\n",
    "    if (not products) and (\"rephrase\" in a and \"english\" in a):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def constraint_checks(products: list, constraints: Optional[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "    \"\"\"Trả về dict các kiểm tra mức tuân thủ ràng buộc.\n",
    "\n",
    "    Ta đánh giá trên `products` trả về (thẻ UI) vì trong project này câu trả lời được suy ra từ chúng.\n",
    "    \"\"\"\n",
    "    constraints = constraints or {}\n",
    "    out: Dict[str, Any] = {}\n",
    "\n",
    "    if not products:\n",
    "        out[\"has_products\"] = False\n",
    "        # Nếu có ràng buộc kỳ vọng nhưng không có sản phẩm, xem như fail.\n",
    "        out[\"constraint_pass\"] = False if constraints else True\n",
    "        return out\n",
    "\n",
    "    out[\"has_products\"] = True\n",
    "\n",
    "    # --- Color ---\n",
    "    if \"color\" in constraints and constraints[\"color\"] is not None:\n",
    "        want = _normalize_color(constraints[\"color\"])\n",
    "        colors = [_normalize_color((p or {}).get(\"color\")) for p in products if isinstance(p, dict)]\n",
    "        # strict: tất cả sản phẩm trả về phải khớp\n",
    "        out[\"color_all_match\"] = all(c == want and c for c in colors)\n",
    "    else:\n",
    "        out[\"color_all_match\"] = None\n",
    "\n",
    "    # --- Usage ---\n",
    "    if \"usage\" in constraints and constraints[\"usage\"] is not None:\n",
    "        want = _normalize_str(constraints[\"usage\"]).lower()\n",
    "        usages = [_normalize_str((p or {}).get(\"usage\")).lower() for p in products if isinstance(p, dict)]\n",
    "        out[\"usage_all_match\"] = all(u == want and u for u in usages)\n",
    "    else:\n",
    "        out[\"usage_all_match\"] = None\n",
    "\n",
    "    # --- Gender ---\n",
    "    if \"gender\" in constraints and constraints[\"gender\"] is not None:\n",
    "        want = _normalize_str(constraints[\"gender\"]).lower()\n",
    "        genders = [_normalize_str((p or {}).get(\"gender\")).lower() for p in products if isinstance(p, dict)]\n",
    "        out[\"gender_all_match\"] = all(g == want and g for g in genders)\n",
    "    else:\n",
    "        out[\"gender_all_match\"] = None\n",
    "\n",
    "    # --- Article type ---\n",
    "    if \"articleType\" in constraints and constraints[\"articleType\"] is not None:\n",
    "        want = _normalize_article_type(constraints[\"articleType\"])\n",
    "        ats = [_normalize_article_type((p or {}).get(\"subcategory\") or (p or {}).get(\"category\") or (p or {}).get(\"articleType\")) for p in products if isinstance(p, dict)]\n",
    "        # LƯU Ý: dataset lưu articleType trong metadata nhưng thẻ API hiện chưa trả về trường này.\n",
    "        # Nếu thiếu, ta không thể kiểm tra một cách đáng tin.\n",
    "        out[\"type_all_match\"] = None if all(a == \"\" for a in ats) else all(a == want for a in ats if a)\n",
    "    else:\n",
    "        out[\"type_all_match\"] = None\n",
    "\n",
    "    # --- Budget ---\n",
    "    prices = _extract_prices(products)\n",
    "    min_p = _safe_float(constraints.get(\"min_price\"))\n",
    "    max_p = _safe_float(constraints.get(\"max_price\"))\n",
    "    if min_p is not None or max_p is not None:\n",
    "        if not prices:\n",
    "            out[\"budget_all_match\"] = False\n",
    "        else:\n",
    "            ok = True\n",
    "            for p in prices:\n",
    "                if min_p is not None and p < min_p - 1e-9:\n",
    "                    ok = False\n",
    "                if max_p is not None and p > max_p + 1e-9:\n",
    "                    ok = False\n",
    "            out[\"budget_all_match\"] = ok\n",
    "    else:\n",
    "        out[\"budget_all_match\"] = None\n",
    "\n",
    "    # Tổng hợp\n",
    "    bool_checks = [v for v in [out.get(\"color_all_match\"), out.get(\"usage_all_match\"), out.get(\"gender_all_match\"), out.get(\"budget_all_match\"), out.get(\"type_all_match\")] if isinstance(v, bool)]\n",
    "    out[\"constraint_pass\"] = all(bool_checks) if bool_checks else True\n",
    "    return out\n",
    "\n",
    "\n",
    "def faithfulness_heuristic(answer: str, products: list) -> Dict[str, Any]:\n",
    "    \"\"\"Kiểm tra groundedness theo heuristic.\n",
    "\n",
    "    Project này tạo câu trả lời (answer) theo cách deterministic từ `products` trong llm_client._answer_from_products,\n",
    "    nên vi phạm thường hiếm. Dù vậy, ta vẫn kiểm tra:\n",
    "    - Nhắc tới ID không có trong products\n",
    "    - Nhắc tới giá không có trong products (rất heuristic)\n",
    "    \"\"\"\n",
    "    ans = answer or \"\"\n",
    "    pids = set(_ids_from_products(products))\n",
    "\n",
    "    # Trích các token như \"(12345)\" hoặc \" 12345 \" làm id.\n",
    "    mentioned = set(re.findall(r\"\\((\\d+)\\)\", ans))\n",
    "    extra_ids = sorted([x for x in mentioned if x not in pids])\n",
    "\n",
    "    # Trích các số dạng $... trong answer\n",
    "    money = [float(x) for x in re.findall(r\"\\$(\\d+(?:\\.\\d{1,2})?)\", ans)]\n",
    "    prices = set(round(p, 2) for p in _extract_prices(products))\n",
    "    # Nếu answer nhắc tới tiền nhưng products không có price, gắn cờ.\n",
    "    money_ok = True\n",
    "    if money and not prices:\n",
    "        money_ok = False\n",
    "    else:\n",
    "        for m in money:\n",
    "            if round(m, 2) not in prices:\n",
    "                # cho phép chênh lệch định dạng nhỏ (số nguyên)\n",
    "                if round(m, 0) not in {round(p, 0) for p in prices}:\n",
    "                    money_ok = False\n",
    "\n",
    "    return {\n",
    "        \"mentioned_ids\": sorted(list(mentioned)),\n",
    "        \"extra_ids_not_in_products\": extra_ids,\n",
    "        \"money_mentions\": money,\n",
    "        \"money_matches_products\": money_ok,\n",
    "        \"faithful\": (len(extra_ids) == 0) and money_ok,\n",
    "    }\n",
    "\n",
    "\n",
    "def pii_safety_heuristic(text: str) -> Dict[str, Any]:\n",
    "    s = text or \"\"\n",
    "    email = re.findall(r\"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\", s)\n",
    "    phone = re.findall(r\"\\b(?:\\+?\\d{1,3}[-.\\s]?)?(?:\\(?\\d{2,4}\\)?[-.\\s]?)?\\d{3,4}[-.\\s]?\\d{3,4}\\b\", s)\n",
    "    cc = re.findall(r\"\\b(?:\\d[ -]*?){13,19}\\b\", s)\n",
    "\n",
    "    # Giảm false positive cho thẻ tín dụng (CC): chỉ giữ chuỗi có >= 13 chữ số\n",
    "    cc_clean = []\n",
    "    for c in cc:\n",
    "        digits = re.sub(r\"\\D\", \"\", c)\n",
    "        if len(digits) >= 13:\n",
    "            cc_clean.append(digits)\n",
    "\n",
    "    return {\n",
    "        \"email_found\": len(email) > 0,\n",
    "        \"phone_found\": len(phone) > 0,\n",
    "        \"cc_like_found\": len(cc_clean) > 0,\n",
    "        \"pii_violation\": (len(email) > 0) or (len(cc_clean) > 0),\n",
    "    }\n",
    "\n",
    "\n",
    "def compute_metrics(df: pd.DataFrame, k_values: List[int] = [1, 3, 5]) -> Tuple[pd.DataFrame, Dict[str, Any]]:\n",
    "    rows = []\n",
    "    for _, r in df.iterrows():\n",
    "        products = r.get(\"products\") or []\n",
    "        sources = r.get(\"sources\") or []\n",
    "        answer = r.get(\"answer\") or \"\"\n",
    "        resp_obj = r.get(\"response\") if \"response\" in df.columns else {}\n",
    "\n",
    "        pred_ids = _ids_from_sources(sources) or _ids_from_products(products)\n",
    "        gold = r.get(\"expected_ids\") or []\n",
    "        gold = [str(x) for x in gold] if isinstance(gold, list) else []\n",
    "\n",
    "        faith = faithfulness_heuristic(answer, products)\n",
    "        constraints = constraint_checks(products, r.get(\"expected_constraints\"))\n",
    "        rejected = english_only_rejected(answer, products, {})\n",
    "        pii = pii_safety_heuristic(answer)\n",
    "\n",
    "        row = {\n",
    "            \"name\": r.get(\"name\"),\n",
    "            \"status\": r.get(\"status\"),\n",
    "            \"latency_ms\": r.get(\"latency_ms\"),\n",
    "            \"n_products\": r.get(\"n_products\"),\n",
    "            \"rejected_english_only\": rejected,\n",
    "            **{f\"faith_{k}\": v for k, v in faith.items()},\n",
    "            **{f\"c_{k}\": v for k, v in constraints.items()},\n",
    "            **{f\"pii_{k}\": v for k, v in pii.items()},\n",
    "        }\n",
    "\n",
    "        for k in k_values:\n",
    "            row[f\"hit@{k}\"] = hit_at_k(pred_ids, gold, k) if gold else float(\"nan\")\n",
    "            row[f\"recall@{k}\"] = recall_at_k(pred_ids, gold, k) if gold else float(\"nan\")\n",
    "            row[f\"ndcg@{k}\"] = ndcg_at_k(pred_ids, gold, k) if gold else float(\"nan\")\n",
    "        row[\"mrr\"] = mrr(pred_ids, gold) if gold else float(\"nan\")\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "    mdf = pd.DataFrame(rows)\n",
    "\n",
    "    # Tổng hợp\n",
    "    summary: Dict[str, Any] = {}\n",
    "\n",
    "    # Thông tin vận hành cơ bản\n",
    "    summary[\"n_cases\"] = int(len(df))\n",
    "    summary[\"error_rate\"] = float((df[\"status\"].fillna(0).astype(int) == 0).mean()) if len(df) else 0.0\n",
    "    summary[\"empty_products_rate\"] = float((df[\"n_products\"].fillna(0).astype(int) == 0).mean()) if len(df) else 0.0\n",
    "\n",
    "    lat = df[\"latency_ms\"].astype(float) if len(df) else pd.Series([], dtype=float)\n",
    "    if len(lat):\n",
    "        summary[\"latency_p50_ms\"] = float(lat.quantile(0.50))\n",
    "        summary[\"latency_p90_ms\"] = float(lat.quantile(0.90))\n",
    "        summary[\"latency_p95_ms\"] = float(lat.quantile(0.95))\n",
    "        summary[\"latency_mean_ms\"] = float(lat.mean())\n",
    "\n",
    "    # Hành vi English-only\n",
    "    if \"should_reject\" in df.columns:\n",
    "        want_reject = df[\"should_reject\"].astype(bool)\n",
    "        got_reject = mdf[\"rejected_english_only\"].astype(bool)\n",
    "        if want_reject.any():\n",
    "            summary[\"english_only_reject_accuracy\"] = float((got_reject[want_reject] == True).mean())\n",
    "\n",
    "    # Ràng buộc\n",
    "    if \"c_constraint_pass\" in mdf.columns:\n",
    "        # Chỉ tính các dòng có ràng buộc (constraints) hoặc có products; ở đây ta lấy trung bình các giá trị boolean khi chúng thực sự là bool.\n",
    "        vals = mdf[\"c_constraint_pass\"].dropna()\n",
    "        if len(vals):\n",
    "            summary[\"constraint_pass_rate\"] = float(vals.astype(bool).mean())\n",
    "\n",
    "    # Tính trung thực (faithfulness)\n",
    "    vals = mdf[\"faith_faithful\"].dropna() if \"faith_faithful\" in mdf.columns else pd.Series([], dtype=bool)\n",
    "    if len(vals):\n",
    "        summary[\"faithfulness_pass_rate\"] = float(vals.astype(bool).mean())\n",
    "\n",
    "    # Retrieval metrics: lấy trung bình trên các dòng có nhãn gold\n",
    "    gold_mask = df[\"expected_ids\"].apply(lambda x: isinstance(x, list) and len(x) > 0)\n",
    "    if gold_mask.any():\n",
    "        for k in k_values:\n",
    "            summary[f\"hit@{k}\"] = float(mdf.loc[gold_mask, f\"hit@{k}\"].mean())\n",
    "            summary[f\"recall@{k}\"] = float(mdf.loc[gold_mask, f\"recall@{k}\"].mean())\n",
    "            summary[f\"ndcg@{k}\"] = float(mdf.loc[gold_mask, f\"ndcg@{k}\"].mean())\n",
    "        summary[\"mrr\"] = float(mdf.loc[gold_mask, \"mrr\"].mean())\n",
    "\n",
    "    return mdf, summary\n",
    "\n",
    "\n",
    "MDF, SUMMARY = compute_metrics(DF)\n",
    "print(json.dumps(SUMMARY, ensure_ascii=False, indent=2))\n",
    "MDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9858b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:\n",
      "- D:\\Study\\CS311\\CS311\\outputs\\eval_results.csv\n",
      "- D:\\Study\\CS311\\CS311\\artifacts\\eval_summary.json\n"
     ]
    }
   ],
   "source": [
    "# 6) Báo cáo + lưu artifacts\n",
    "\n",
    "# Ghép (merge) metrics trở lại DF chính để tiện theo dõi\n",
    "OUT = DF.merge(MDF, on=\"name\", how=\"left\", suffixes=(\"\", \"_m\"))\n",
    "\n",
    "csv_path = OUTPUTS_DIR / \"eval_results.csv\"\n",
    "OUT.to_csv(csv_path, index=False, encoding=\"utf-8\")\n",
    "(ARTIFACTS_DIR / \"eval_summary.json\").write_text(json.dumps(SUMMARY, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\"-\", csv_path.resolve())\n",
    "print(\"-\", (ARTIFACTS_DIR / \"eval_summary.json\").resolve())\n",
    "\n",
    "# Hiển thị gọn\n",
    "cols_show = [\n",
    "    \"name\",\n",
    "    \"status\",\n",
    "    \"latency_ms\",\n",
    "    \"n_products\",\n",
    "    \"should_reject\",\n",
    "    \"rejected_english_only\",\n",
    "    \"c_constraint_pass\",\n",
    "    \"faith_faithful\",\n",
    "]\n",
    "cols_show = [c for c in cols_show if c in OUT.columns]\n",
    "OUT[cols_show]\n",
    "\n",
    "\n",
    "# (Tuỳ chọn) Vẽ histogram độ trễ\n",
    "if plt is not None and len(OUT):\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    plt.hist(OUT[\"latency_ms\"].astype(float), bins=20)\n",
    "    plt.title(\"Histogram độ trễ (ms)\")\n",
    "    plt.xlabel(\"ms\")\n",
    "    plt.ylabel(\"số lượng\")\n",
    "    plt.grid(True, alpha=0.2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b1de11",
   "metadata": {},
   "source": [
    "## Bổ sung: làm thế nào để có *nhãn chuẩn (gold)* cho các chỉ số truy hồi (retrieval metrics)?\n",
    "\n",
    "Vì dataset `styles.csv` khá lớn, cách thực tế nhất là:\n",
    "\n",
    "1) Chạy vài query tiêu biểu.\n",
    "2) Nhìn top kết quả trong `products`/`sources`.\n",
    "3) Chọn 1–3 `product id` bạn xem là **đúng nhất** → điền vào `expected_ids` trong `TESTSET`.\n",
    "\n",
    "Sau đó chạy lại notebook để có **Hit@K / MRR / nDCG**.\n",
    "\n",
    "---\n",
    "\n",
    "## (Tuỳ chọn) Metrics theo câu trả lời tham chiếu (BLEU/ROUGE/BERTScore)\n",
    "\n",
    "Trong dự án hiện tại, câu trả lời `answer` được tạo “deterministic/định sẵn” từ `products` (để tránh hallucination), nên các metric theo câu trả lời tham chiếu thường **không phản ánh đúng** chất lượng tìm kiếm.\n",
    "\n",
    "Nếu bạn có bộ `reference` (ví dụ: câu trả lời mẫu do người chấm viết), bạn có thể thêm cột `reference` vào test cases và cài thêm thư viện như `sacrebleu`, `rouge_score`, `bert_score` để tính.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f67c57f",
   "metadata": {},
   "source": [
    "## C) Đánh giá Image RAG (tìm kiếm bằng ảnh)\n",
    "\n",
    "Hệ của bạn có endpoint `POST /search/image/upload` (embed ảnh bằng OpenCLIP và truy vấn collection `products_image`).\n",
    "\n",
    "### Tư tưởng đánh giá “tối ưu” cho Image RAG\n",
    "\n",
    "1) **Self-retrieval**: lấy một ảnh từ dataset làm query → kết quả top-K có chứa **chính id của ảnh đó**.\n",
    "   - Đây là dạng *nhãn gold* rẻ nhất vì không cần gán nhãn thủ công.\n",
    "\n",
    "2) **Robustness**: áp dụng vài biến đổi nhẹ (resize/crop/brightness) lên ảnh query → vẫn hit được id.\n",
    "\n",
    "3) **Hiệu năng**: latency p50/p95 cho endpoint ảnh.\n",
    "\n",
    "> Điều kiện: bạn cần ingest ảnh trước (chạy `ingest_images.py` hoặc gọi `POST /ingest_image`). Nếu chưa ingest, endpoint ảnh có thể trả kết quả rỗng hoặc lỗi.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9752c543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMAGE_DIR=datasets\\archive\\fashion-dataset\\images exists=True | cases=20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>image</th>\n",
       "      <th>expected_id</th>\n",
       "      <th>top_k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_10000</td>\n",
       "      <td>datasets\\archive\\fashion-dataset\\images\\10000.jpg</td>\n",
       "      <td>10000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_10001</td>\n",
       "      <td>datasets\\archive\\fashion-dataset\\images\\10001.jpg</td>\n",
       "      <td>10001</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_10002</td>\n",
       "      <td>datasets\\archive\\fashion-dataset\\images\\10002.jpg</td>\n",
       "      <td>10002</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name                                              image expected_id  \\\n",
       "0  img_10000  datasets\\archive\\fashion-dataset\\images\\10000.jpg       10000   \n",
       "1  img_10001  datasets\\archive\\fashion-dataset\\images\\10001.jpg       10001   \n",
       "2  img_10002  datasets\\archive\\fashion-dataset\\images\\10002.jpg       10002   \n",
       "\n",
       "   top_k  \n",
       "0      5  \n",
       "1      5  \n",
       "2      5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# C.1) Tiện ích gọi endpoint ảnh + tạo testset tự động\n",
    "\n",
    "import io\n",
    "from dataclasses import dataclass\n",
    "\n",
    "try:\n",
    "    from PIL import Image, ImageEnhance\n",
    "except Exception:\n",
    "    Image = None\n",
    "    ImageEnhance = None\n",
    "\n",
    "\n",
    "IMAGE_DIR = Path(os.getenv(\"EVAL_IMAGE_DIR\", \"datasets/archive/fashion-dataset/images\"))\n",
    "IMAGE_TOP_K = int(os.getenv(\"EVAL_IMAGE_TOP_K\", \"5\"))\n",
    "IMAGE_N_SAMPLES = int(os.getenv(\"EVAL_IMAGE_N_SAMPLES\", \"20\"))\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ImageTestCase:\n",
    "    name: str\n",
    "    image_path: Path\n",
    "    expected_id: Optional[str] = None\n",
    "    top_k: int = IMAGE_TOP_K\n",
    "\n",
    "\n",
    "def _list_image_files(img_dir: Path) -> List[Path]:\n",
    "    if not img_dir.exists():\n",
    "        return []\n",
    "    exts = {\".jpg\", \".jpeg\", \".png\"}\n",
    "    files = [p for p in img_dir.glob(\"*\") if p.suffix.lower() in exts]\n",
    "    files.sort(key=lambda p: p.name)\n",
    "    return files\n",
    "\n",
    "\n",
    "def _expected_id_from_filename(p: Path) -> Optional[str]:\n",
    "    # dataset dùng định dạng <id>.jpg\n",
    "    m = re.match(r\"^(\\d+)\", p.stem)\n",
    "    return m.group(1) if m else None\n",
    "\n",
    "\n",
    "def call_image_search_file(image_path: Path, top_k: int = 5) -> dict:\n",
    "    \"\"\"Gọi POST /search/image/upload với file local.\n",
    "\n",
    "    Trả về dict gồm: status, latency_ms, error, response\n",
    "    \"\"\"\n",
    "    url = f\"{API_BASE}/search/image/upload\"\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    try:\n",
    "        with image_path.open(\"rb\") as f:\n",
    "            files = {\"file\": (image_path.name, f, \"application/octet-stream\")}\n",
    "            resp = requests.post(url, files=files, params={\"top_k\": int(top_k)}, timeout=TIMEOUT_S)\n",
    "        latency_ms = (time.perf_counter() - t0) * 1000\n",
    "        try:\n",
    "            data = resp.json()\n",
    "        except Exception:\n",
    "            data = {\"_raw\": resp.text}\n",
    "\n",
    "        err = None\n",
    "        if not (200 <= resp.status_code < 300):\n",
    "            err = f\"HTTP {resp.status_code}: {data}\"\n",
    "\n",
    "        return {\"status\": resp.status_code, \"latency_ms\": latency_ms, \"error\": err, \"response\": data}\n",
    "    except Exception as e:\n",
    "        latency_ms = (time.perf_counter() - t0) * 1000\n",
    "        return {\"status\": 0, \"latency_ms\": latency_ms, \"error\": f\"{type(e).__name__}: {e}\", \"response\": {}}\n",
    "\n",
    "\n",
    "def call_image_search_bytes(image_bytes: bytes, filename: str = \"query.jpg\", top_k: int = 5) -> dict:\n",
    "    \"\"\"Gọi POST /search/image/upload với bytes (phục vụ các biến thể robustness).\"\"\"\n",
    "    url = f\"{API_BASE}/search/image/upload\"\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    try:\n",
    "        bio = io.BytesIO(image_bytes)\n",
    "        files = {\"file\": (filename, bio, \"application/octet-stream\")}\n",
    "        resp = requests.post(url, files=files, params={\"top_k\": int(top_k)}, timeout=TIMEOUT_S)\n",
    "        latency_ms = (time.perf_counter() - t0) * 1000\n",
    "        try:\n",
    "            data = resp.json()\n",
    "        except Exception:\n",
    "            data = {\"_raw\": resp.text}\n",
    "\n",
    "        err = None\n",
    "        if not (200 <= resp.status_code < 300):\n",
    "            err = f\"HTTP {resp.status_code}: {data}\"\n",
    "\n",
    "        return {\"status\": resp.status_code, \"latency_ms\": latency_ms, \"error\": err, \"response\": data}\n",
    "    except Exception as e:\n",
    "        latency_ms = (time.perf_counter() - t0) * 1000\n",
    "        return {\"status\": 0, \"latency_ms\": latency_ms, \"error\": f\"{type(e).__name__}: {e}\", \"response\": {}}\n",
    "\n",
    "\n",
    "def build_image_testset(n_samples: int = 20) -> List[ImageTestCase]:\n",
    "    files = _list_image_files(IMAGE_DIR)\n",
    "    if not files:\n",
    "        return []\n",
    "\n",
    "    # Lấy mẫu cố định: chọn N file đầu (ổn định giữa các lần chạy)\n",
    "    pick = files[: max(1, min(n_samples, len(files)))]\n",
    "    out = []\n",
    "    for p in pick:\n",
    "        out.append(\n",
    "            ImageTestCase(\n",
    "                name=f\"img_{p.stem}\",\n",
    "                image_path=p,\n",
    "                expected_id=_expected_id_from_filename(p),\n",
    "                top_k=IMAGE_TOP_K,\n",
    "            )\n",
    "        )\n",
    "    return out\n",
    "\n",
    "\n",
    "IMAGE_TESTSET = build_image_testset(IMAGE_N_SAMPLES)\n",
    "print(f\"IMAGE_DIR={IMAGE_DIR} exists={IMAGE_DIR.exists()} | cases={len(IMAGE_TESTSET)}\")\n",
    "if IMAGE_TESTSET[:3]:\n",
    "    display(pd.DataFrame([{\"name\": t.name, \"image\": str(t.image_path), \"expected_id\": t.expected_id, \"top_k\": t.top_k} for t in IMAGE_TESTSET[:3]]))\n",
    "else:\n",
    "    print(\"[HINT] Không tìm thấy ảnh. Hãy kiểm tra EVAL_IMAGE_DIR hoặc đường dẫn dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ac1337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>variant</th>\n",
       "      <th>image</th>\n",
       "      <th>expected_id</th>\n",
       "      <th>status</th>\n",
       "      <th>latency_ms</th>\n",
       "      <th>error</th>\n",
       "      <th>pred_ids</th>\n",
       "      <th>n_results</th>\n",
       "      <th>hit@1</th>\n",
       "      <th>recall@1</th>\n",
       "      <th>ndcg@1</th>\n",
       "      <th>hit@3</th>\n",
       "      <th>recall@3</th>\n",
       "      <th>ndcg@3</th>\n",
       "      <th>hit@5</th>\n",
       "      <th>recall@5</th>\n",
       "      <th>ndcg@5</th>\n",
       "      <th>mrr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_10000</td>\n",
       "      <td>orig</td>\n",
       "      <td>datasets\\archive\\fashion-dataset\\images\\10000.jpg</td>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>30014.2030</td>\n",
       "      <td>ReadTimeout: HTTPConnectionPool(host='127.0.0....</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_10001</td>\n",
       "      <td>orig</td>\n",
       "      <td>datasets\\archive\\fashion-dataset\\images\\10001.jpg</td>\n",
       "      <td>10001</td>\n",
       "      <td>0</td>\n",
       "      <td>30004.3613</td>\n",
       "      <td>ReadTimeout: HTTPConnectionPool(host='127.0.0....</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_10002</td>\n",
       "      <td>orig</td>\n",
       "      <td>datasets\\archive\\fashion-dataset\\images\\10002.jpg</td>\n",
       "      <td>10002</td>\n",
       "      <td>200</td>\n",
       "      <td>1152.1375</td>\n",
       "      <td>None</td>\n",
       "      <td>[10002, 41000, 41001, 38503, 38938]</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_10003</td>\n",
       "      <td>orig</td>\n",
       "      <td>datasets\\archive\\fashion-dataset\\images\\10003.jpg</td>\n",
       "      <td>10003</td>\n",
       "      <td>200</td>\n",
       "      <td>150.0781</td>\n",
       "      <td>None</td>\n",
       "      <td>[10003, 22627, 22579, 22600, 17923]</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_10004</td>\n",
       "      <td>orig</td>\n",
       "      <td>datasets\\archive\\fashion-dataset\\images\\10004.jpg</td>\n",
       "      <td>10004</td>\n",
       "      <td>200</td>\n",
       "      <td>220.5692</td>\n",
       "      <td>None</td>\n",
       "      <td>[10004, 38566, 32648, 14024, 38568]</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name variant                                              image  \\\n",
       "0  img_10000    orig  datasets\\archive\\fashion-dataset\\images\\10000.jpg   \n",
       "1  img_10001    orig  datasets\\archive\\fashion-dataset\\images\\10001.jpg   \n",
       "2  img_10002    orig  datasets\\archive\\fashion-dataset\\images\\10002.jpg   \n",
       "3  img_10003    orig  datasets\\archive\\fashion-dataset\\images\\10003.jpg   \n",
       "4  img_10004    orig  datasets\\archive\\fashion-dataset\\images\\10004.jpg   \n",
       "\n",
       "  expected_id  status  latency_ms  \\\n",
       "0       10000       0  30014.2030   \n",
       "1       10001       0  30004.3613   \n",
       "2       10002     200   1152.1375   \n",
       "3       10003     200    150.0781   \n",
       "4       10004     200    220.5692   \n",
       "\n",
       "                                               error  \\\n",
       "0  ReadTimeout: HTTPConnectionPool(host='127.0.0....   \n",
       "1  ReadTimeout: HTTPConnectionPool(host='127.0.0....   \n",
       "2                                               None   \n",
       "3                                               None   \n",
       "4                                               None   \n",
       "\n",
       "                              pred_ids  n_results  hit@1  recall@1  ndcg@1  \\\n",
       "0                                   []          0    0.0       0.0     0.0   \n",
       "1                                   []          0    0.0       0.0     0.0   \n",
       "2  [10002, 41000, 41001, 38503, 38938]          5    1.0       1.0     1.0   \n",
       "3  [10003, 22627, 22579, 22600, 17923]          5    1.0       1.0     1.0   \n",
       "4  [10004, 38566, 32648, 14024, 38568]          5    1.0       1.0     1.0   \n",
       "\n",
       "   hit@3  recall@3  ndcg@3  hit@5  recall@5  ndcg@5  mrr  \n",
       "0    0.0       0.0     0.0    0.0       0.0     0.0  0.0  \n",
       "1    0.0       0.0     0.0    0.0       0.0     0.0  0.0  \n",
       "2    1.0       1.0     1.0    1.0       1.0     1.0  1.0  \n",
       "3    1.0       1.0     1.0    1.0       1.0     1.0  1.0  \n",
       "4    1.0       1.0     1.0    1.0       1.0     1.0  1.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# C.2) Các biến thể robustness (tuỳ chọn) + runner\n",
    "\n",
    "\n",
    "def make_variants(image_path: Path) -> Dict[str, bytes]:\n",
    "    \"\"\"Trả về dict variant_name -> bytes ảnh đã encode.\n",
    "\n",
    "    Nếu không có PIL, chỉ trả về bytes gốc.\n",
    "    \"\"\"\n",
    "    raw = image_path.read_bytes()\n",
    "    variants: Dict[str, bytes] = {\"orig\": raw}\n",
    "\n",
    "    if Image is None:\n",
    "        return variants\n",
    "\n",
    "    try:\n",
    "        img = Image.open(io.BytesIO(raw)).convert(\"RGB\")\n",
    "    except Exception:\n",
    "        return variants\n",
    "\n",
    "    # LƯU Ý: tránh tham chiếu Image.Image trong type annotation vì notebook này\n",
    "    # cố ý đặt Image=None khi Pillow chưa được cài; điều đó có thể làm một số linter bị rối.\n",
    "    def _to_jpeg_bytes(im, quality: int = 90) -> bytes:\n",
    "        b = io.BytesIO()\n",
    "        im.save(b, format=\"JPEG\", quality=quality)\n",
    "        return b.getvalue()\n",
    "\n",
    "    # Thu nhỏ (mô phỏng thumbnail)\n",
    "    try:\n",
    "        im = img.copy()\n",
    "        im.thumbnail((224, 224))\n",
    "        variants[\"thumb_224\"] = _to_jpeg_bytes(im)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Cắt giữa thành hình vuông\n",
    "    try:\n",
    "        im = img.copy()\n",
    "        w, h = im.size\n",
    "        side = min(w, h)\n",
    "        left = (w - side) // 2\n",
    "        top = (h - side) // 2\n",
    "        im = im.crop((left, top, left + side, top + side)).resize((224, 224))\n",
    "        variants[\"center_crop_224\"] = _to_jpeg_bytes(im)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Tăng/giảm độ sáng\n",
    "    if ImageEnhance is not None:\n",
    "        try:\n",
    "            variants[\"bright_1p2\"] = _to_jpeg_bytes(ImageEnhance.Brightness(img).enhance(1.2))\n",
    "        except Exception:\n",
    "            pass\n",
    "        try:\n",
    "            variants[\"bright_0p8\"] = _to_jpeg_bytes(ImageEnhance.Brightness(img).enhance(0.8))\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # Lật ngang\n",
    "    try:\n",
    "        variants[\"flip_lr\"] = _to_jpeg_bytes(img.transpose(Image.FLIP_LEFT_RIGHT))\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    return variants\n",
    "\n",
    "\n",
    "def _ids_from_image_results(resp: dict) -> List[str]:\n",
    "    results = (resp or {}).get(\"results\") or []\n",
    "    out: List[str] = []\n",
    "    for r in results:\n",
    "        if isinstance(r, dict) and r.get(\"id\") is not None:\n",
    "            out.append(str(r.get(\"id\")))\n",
    "    return out\n",
    "\n",
    "\n",
    "def run_image_eval(testset: List[ImageTestCase], k_values: List[int] = [1, 3, 5], with_variants: bool = True) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    iterator = tqdm(testset, desc=\"Đánh giá ảnh\") if tqdm else testset\n",
    "\n",
    "    for tc in iterator:\n",
    "        if not tc.image_path.exists():\n",
    "            rows.append({\"name\": tc.name, \"status\": 0, \"error\": \"missing_file\", \"image\": str(tc.image_path)})\n",
    "            continue\n",
    "\n",
    "        expected = tc.expected_id\n",
    "        gold = [expected] if expected else []\n",
    "\n",
    "        if with_variants:\n",
    "            var_map = make_variants(tc.image_path)\n",
    "        else:\n",
    "            var_map = {\"orig\": tc.image_path.read_bytes()}\n",
    "\n",
    "        for vname, vbytes in var_map.items():\n",
    "            res = call_image_search_bytes(vbytes, filename=f\"{tc.image_path.stem}_{vname}.jpg\", top_k=tc.top_k)\n",
    "            pred_ids = _ids_from_image_results(res.get(\"response\") or {})\n",
    "\n",
    "            row = {\n",
    "                \"name\": tc.name,\n",
    "                \"variant\": vname,\n",
    "                \"image\": str(tc.image_path),\n",
    "                \"expected_id\": expected,\n",
    "                \"status\": res.get(\"status\"),\n",
    "                \"latency_ms\": float(res.get(\"latency_ms\") or 0.0),\n",
    "                \"error\": res.get(\"error\"),\n",
    "                \"pred_ids\": pred_ids,\n",
    "                \"n_results\": len(pred_ids),\n",
    "            }\n",
    "            for k in k_values:\n",
    "                row[f\"hit@{k}\"] = hit_at_k(pred_ids, gold, k) if gold else float(\"nan\")\n",
    "                row[f\"recall@{k}\"] = recall_at_k(pred_ids, gold, k) if gold else float(\"nan\")\n",
    "                row[f\"ndcg@{k}\"] = ndcg_at_k(pred_ids, gold, k) if gold else float(\"nan\")\n",
    "            row[\"mrr\"] = mrr(pred_ids, gold) if gold else float(\"nan\")\n",
    "\n",
    "            rows.append(row)\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "IMG_DF = run_image_eval(IMAGE_TESTSET, with_variants=True)\n",
    "IMG_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e43675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"n_rows\": 20,\n",
      "  \"n_cases\": 20,\n",
      "  \"error_rate\": 0.1,\n",
      "  \"empty_results_rate\": 0.1,\n",
      "  \"latency_p50_ms\": 150.89359999910812,\n",
      "  \"latency_p90_ms\": 4037.3598800012087,\n",
      "  \"latency_p95_ms\": 30004.85338500148,\n",
      "  \"latency_mean_ms\": 3186.539654999433,\n",
      "  \"hit@1\": 0.9,\n",
      "  \"hit@3\": 0.9,\n",
      "  \"hit@5\": 0.9,\n",
      "  \"mrr\": 0.9,\n",
      "  \"per_variant\": [\n",
      "    {\n",
      "      \"variant\": \"orig\",\n",
      "      \"mrr\": 0.9,\n",
      "      \"hit@1\": 0.9,\n",
      "      \"hit@3\": 0.9,\n",
      "      \"hit@5\": 0.9\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Saved:\n",
      "- D:\\Study\\CS311\\CS311\\outputs\\eval_image_results.csv\n",
      "- D:\\Study\\CS311\\CS311\\artifacts\\image_eval_summary.json\n"
     ]
    }
   ],
   "source": [
    "# C.3) Tổng hợp metrics cho Image RAG + xuất artifacts\n",
    "\n",
    "\n",
    "def summarize_image_eval(img_df: pd.DataFrame, k_values: List[int] = [1, 3, 5]) -> Dict[str, Any]:\n",
    "    if img_df is None or len(img_df) == 0:\n",
    "        return {\"n_rows\": 0}\n",
    "\n",
    "    out: Dict[str, Any] = {\n",
    "        \"n_rows\": int(len(img_df)),\n",
    "        \"n_cases\": int(img_df[\"name\"].nunique()) if \"name\" in img_df.columns else None,\n",
    "        \"error_rate\": float((img_df[\"status\"].fillna(0).astype(int) == 0).mean()) if \"status\" in img_df.columns else None,\n",
    "        \"empty_results_rate\": float((img_df[\"n_results\"].fillna(0).astype(int) == 0).mean()) if \"n_results\" in img_df.columns else None,\n",
    "    }\n",
    "\n",
    "    if \"latency_ms\" in img_df.columns:\n",
    "        lat = img_df[\"latency_ms\"].astype(float)\n",
    "        out.update(\n",
    "            {\n",
    "                \"latency_p50_ms\": float(lat.quantile(0.50)),\n",
    "                \"latency_p90_ms\": float(lat.quantile(0.90)),\n",
    "                \"latency_p95_ms\": float(lat.quantile(0.95)),\n",
    "                \"latency_mean_ms\": float(lat.mean()),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    for k in k_values:\n",
    "        col = f\"hit@{k}\"\n",
    "        if col in img_df.columns:\n",
    "            out[col] = float(img_df[col].mean())\n",
    "\n",
    "    if \"mrr\" in img_df.columns:\n",
    "        out[\"mrr\"] = float(img_df[\"mrr\"].mean())\n",
    "\n",
    "    # (Tuỳ chọn) Tổng hợp theo từng biến thể\n",
    "    if \"variant\" in img_df.columns:\n",
    "        per_variant = (\n",
    "            img_df.groupby(\"variant\")[[c for c in [\"mrr\"] + [f\"hit@{k}\" for k in k_values] if c in img_df.columns]]\n",
    "            .mean(numeric_only=True)\n",
    "            .reset_index()\n",
    "        )\n",
    "        out[\"per_variant\"] = per_variant.to_dict(orient=\"records\")\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "IMG_SUMMARY = summarize_image_eval(IMG_DF)\n",
    "print(json.dumps(IMG_SUMMARY, ensure_ascii=False, indent=2))\n",
    "\n",
    "img_csv = OUTPUTS_DIR / \"eval_image_results.csv\"\n",
    "IMG_DF.to_csv(img_csv, index=False, encoding=\"utf-8\")\n",
    "(ARTIFACTS_DIR / \"image_eval_summary.json\").write_text(json.dumps(IMG_SUMMARY, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\"-\", img_csv.resolve())\n",
    "print(\"-\", (ARTIFACTS_DIR / \"image_eval_summary.json\").resolve())\n",
    "\n",
    "# (Tuỳ chọn) Vẽ biểu đồ\n",
    "if plt is not None and len(IMG_DF) and \"latency_ms\" in IMG_DF.columns:\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    plt.hist(IMG_DF[\"latency_ms\"].astype(float), bins=20)\n",
    "    plt.title(\"Histogram độ trễ tìm kiếm ảnh (ms)\")\n",
    "    plt.xlabel(\"ms\")\n",
    "    plt.ylabel(\"số lượng\")\n",
    "    plt.grid(True, alpha=0.2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a662a72b",
   "metadata": {},
   "source": [
    "## Đánh giá LLM (text) (rubric + judge tuỳ chọn + tỷ lệ thắng A/B)\n",
    "\n",
    "Phần này tập trung đánh giá **chất lượng câu trả lời dạng text**.\n",
    "\n",
    "Vì hệ hiện tại tạo `answer` từ `products` (deterministic/định sẵn), nên đánh giá “tối ưu” cho text là:\n",
    "\n",
    "1) **Chấm rubric (theo luật / rule-based)**: rẻ, ổn định, chạy được trong CI.\n",
    "2) **LLM làm giám khảo (tuỳ chọn)**: chỉ bật khi bạn cấu hình `LLM_*` để chấm các tiêu chí mềm (usefulness, clarity…).\n",
    "3) **Tỷ lệ thắng A/B**: so 2 phiên bản API (A và B) theo tỷ lệ thắng (so sánh cặp/pairwise).\n",
    "\n",
    "### Khi nào dùng A/B?\n",
    "- Khi bạn thay đổi embedding model, threshold lọc, prompt, hoặc bật LLM sinh (generative).\n",
    "- A và B nên là **hai base URL khác nhau** (vd 2 container / 2 nhánh config).\n",
    "\n",
    "> Cấu hình: đặt `API_BASE_A` và `API_BASE_B` trong environment. Nếu không đặt, sẽ dùng `API_BASE` hiện tại.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a89ae46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>rubric_faithfulness</th>\n",
       "      <th>rubric_format</th>\n",
       "      <th>rubric_completeness</th>\n",
       "      <th>rubric_constraint</th>\n",
       "      <th>rubric_conciseness</th>\n",
       "      <th>rubric_total</th>\n",
       "      <th>rubric_pick_count</th>\n",
       "      <th>rubric_answer_chars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>basic_men_shoes_budget</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>formal_office</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>color_strict</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>type_tshirts</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>reject_vietnamese</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     name  rubric_faithfulness  rubric_format  \\\n",
       "0  basic_men_shoes_budget                    2              2   \n",
       "1           formal_office                    0              2   \n",
       "2            color_strict                    2              2   \n",
       "3            type_tshirts                    2              2   \n",
       "4       reject_vietnamese                    2              0   \n",
       "\n",
       "   rubric_completeness  rubric_constraint  rubric_conciseness  rubric_total  \\\n",
       "0                    2                  2                   2            10   \n",
       "1                    2                  2                   2             8   \n",
       "2                    2                  2                   2            10   \n",
       "3                    2                  1                   2             9   \n",
       "4                    0                  2                   2             6   \n",
       "\n",
       "   rubric_pick_count  rubric_answer_chars  \n",
       "0                  4                  594  \n",
       "1                  4                  586  \n",
       "2                  4                  543  \n",
       "3                  4                  561  \n",
       "4                  0                   54  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rule-based rubric avg:\n",
      "rubric_faithfulness      1.6\n",
      "rubric_format            1.6\n",
      "rubric_completeness      1.6\n",
      "rubric_constraint        1.8\n",
      "rubric_conciseness       2.0\n",
      "rubric_total             8.6\n",
      "rubric_pick_count        3.2\n",
      "rubric_answer_chars    467.6\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# T.1) Chấm rubric theo luật (rule-based)\n",
    "\n",
    "# Giữ phần này ít phụ thuộc: chỉ dùng stdlib + pandas.\n",
    "\n",
    "API_BASE_A = os.getenv(\"API_BASE_A\", API_BASE).rstrip(\"/\")\n",
    "API_BASE_B = os.getenv(\"API_BASE_B\", \"\").rstrip(\"/\")\n",
    "\n",
    "\n",
    "def _extract_pick_lines(answer: str) -> List[str]:\n",
    "    \"\"\"Trích các dòng trông giống danh sách đánh số: '1) ...'\"\"\"\n",
    "    lines = (answer or \"\").splitlines()\n",
    "    picks = []\n",
    "    for ln in lines:\n",
    "        if re.match(r\"^\\s*\\d+\\)\\s+\", ln):\n",
    "            picks.append(ln.strip())\n",
    "    return picks\n",
    "\n",
    "\n",
    "def rubric_score_rule_based(\n",
    "    query: str,\n",
    "    answer: str,\n",
    "    products: list,\n",
    "    expected_constraints: Optional[Dict[str, Any]] = None,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Trả về điểm rubric (0..2) bằng các luật deterministic.\n",
    "\n",
    "    Các chiều (0..2):\n",
    "    - faithfulness: nhất quán với products (dùng heuristic hiện có)\n",
    "    - format: có mục 'Top picks' với các dòng đánh số\n",
    "    - completeness: nhắc 2–4 lựa chọn và có id cho mỗi lựa chọn\n",
    "    - constraint_support: nếu có ràng buộc, products trả về phải đáp ứng\n",
    "    - conciseness: không quá dài / không rỗng\n",
    "\n",
    "    Lưu ý: với 'constraint_support' ta dùng lại constraint_checks() (kiểm tra trên products trả về).\n",
    "    \"\"\"\n",
    "    ans = answer or \"\"\n",
    "\n",
    "    # Tính trung thực (faithfulness)\n",
    "    faith = faithfulness_heuristic(ans, products)\n",
    "    faithfulness = 2 if faith.get(\"faithful\") else 0\n",
    "\n",
    "    # Định dạng (format)\n",
    "    picks = _extract_pick_lines(ans)\n",
    "    has_top_picks_header = bool(re.search(r\"(?im)^\\s*top\\s+picks\\s*:\\s*$\", ans))\n",
    "    if has_top_picks_header and len(picks) >= 2:\n",
    "        format_score = 2\n",
    "    elif len(picks) >= 1:\n",
    "        format_score = 1\n",
    "    else:\n",
    "        format_score = 0\n",
    "\n",
    "    # Độ đầy đủ (completeness)\n",
    "    # Mong muốn có 2–4 id khác nhau được nhắc dưới dạng '(123)'\n",
    "    mentioned_ids = set(re.findall(r\"\\((\\d+)\\)\", ans))\n",
    "    prod_ids = set(_ids_from_products(products))\n",
    "    mentioned_valid = [x for x in mentioned_ids if x in prod_ids]\n",
    "    if 2 <= len(picks) <= 4 and len(mentioned_valid) >= min(2, len(prod_ids)):\n",
    "        completeness = 2\n",
    "    elif len(picks) >= 1:\n",
    "        completeness = 1\n",
    "    else:\n",
    "        completeness = 0\n",
    "\n",
    "    # Hỗ trợ ràng buộc (constraint support)\n",
    "    c = constraint_checks(products, expected_constraints)\n",
    "    constraint_support = 2 if c.get(\"constraint_pass\") else (1 if c.get(\"has_products\") else 0)\n",
    "\n",
    "    # Độ súc tích (conciseness)\n",
    "    n_chars = len(ans.strip())\n",
    "    if n_chars == 0:\n",
    "        conciseness = 0\n",
    "    elif n_chars <= 1200:\n",
    "        conciseness = 2\n",
    "    else:\n",
    "        conciseness = 1\n",
    "\n",
    "    total = faithfulness + format_score + completeness + constraint_support + conciseness\n",
    "\n",
    "    return {\n",
    "        \"rubric_faithfulness\": faithfulness,\n",
    "        \"rubric_format\": format_score,\n",
    "        \"rubric_completeness\": completeness,\n",
    "        \"rubric_constraint\": constraint_support,\n",
    "        \"rubric_conciseness\": conciseness,\n",
    "        \"rubric_total\": total,\n",
    "        # các trường debug hữu ích\n",
    "        \"rubric_pick_count\": len(picks),\n",
    "        \"rubric_answer_chars\": n_chars,\n",
    "    }\n",
    "\n",
    "\n",
    "def score_df_rule_based(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for _, r in df.iterrows():\n",
    "        rs = rubric_score_rule_based(\n",
    "            query=r.get(\"query\") or \"\",\n",
    "            answer=r.get(\"answer\") or \"\",\n",
    "            products=r.get(\"products\") or [],\n",
    "            expected_constraints=r.get(\"expected_constraints\"),\n",
    "        )\n",
    "        rows.append({\"name\": r.get(\"name\"), **rs})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "RUBRIC_DF = score_df_rule_based(DF)\n",
    "display(RUBRIC_DF)\n",
    "print(\"Trung bình rubric (theo luật):\")\n",
    "print(RUBRIC_DF[[c for c in RUBRIC_DF.columns if c.startswith('rubric_')]].mean(numeric_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5b0764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'llm_judge_enabled': True, 'LLM_BASE_URL': 'https://router.huggingface.co/v1', 'LLM_MODEL': 'meta-llama/Llama-3.1-8B-Instruct'}\n"
     ]
    }
   ],
   "source": [
    "# T.2) LLM làm giám khảo (tuỳ chọn, bật khi có LLM_*)\n",
    "\n",
    "# Hỗ trợ endpoint tương thích OpenAI thông qua package Python `openai`.\n",
    "# Project đã có dependency `openai` trong requirements.txt.\n",
    "\n",
    "LLM_BASE_URL = (os.getenv(\"LLM_BASE_URL\", \"\") or \"\").strip()\n",
    "LLM_API_KEY = (os.getenv(\"LLM_API_KEY\", \"\") or \"\").strip()\n",
    "LLM_MODEL = (os.getenv(\"LLM_MODEL\", \"\") or \"\").strip()\n",
    "\n",
    "\n",
    "def _llm_judge_enabled() -> bool:\n",
    "    return bool(LLM_API_KEY and LLM_MODEL)\n",
    "\n",
    "\n",
    "def _get_openai_client_for_judge():\n",
    "    from openai import OpenAI\n",
    "\n",
    "    base_url = LLM_BASE_URL.strip() or \"https://api.openai.com/v1\"\n",
    "    return OpenAI(base_url=base_url, api_key=LLM_API_KEY)\n",
    "\n",
    "\n",
    "def llm_judge_pairwise(\n",
    "    query: str,\n",
    "    a: Dict[str, Any],\n",
    "    b: Dict[str, Any],\n",
    "    max_tokens: int = 400,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Chấm theo cặp (pairwise) giữa hệ A và hệ B.\n",
    "\n",
    "    Đầu vào a/b cần có:\n",
    "    - answer: str\n",
    "    - products: list[dict]\n",
    "\n",
    "    Trả về dict với winner thuộc {\"A\",\"B\",\"TIE\"} và điểm theo từng tiêu chí.\n",
    "    \"\"\"\n",
    "    if not _llm_judge_enabled():\n",
    "        return {\"enabled\": False, \"winner\": \"TIE\", \"reason\": \"Tắt LLM judge (thiếu LLM_API_KEY/LLM_MODEL)\"}\n",
    "\n",
    "    # Giữ products gọn để giảm kích thước prompt và tránh đưa vào các trường không liên quan.\n",
    "    def slim_products(ps: list) -> list:\n",
    "        out = []\n",
    "        for p in ps or []:\n",
    "            if not isinstance(p, dict):\n",
    "                continue\n",
    "            out.append(\n",
    "                {\n",
    "                    \"id\": p.get(\"id\"),\n",
    "                    \"name\": p.get(\"name\"),\n",
    "                    \"price\": p.get(\"price\"),\n",
    "                    \"color\": p.get(\"color\"),\n",
    "                    \"gender\": p.get(\"gender\"),\n",
    "                    \"category\": p.get(\"category\"),\n",
    "                    \"subcategory\": p.get(\"subcategory\"),\n",
    "                    \"usage\": p.get(\"usage\"),\n",
    "                }\n",
    "            )\n",
    "        return out\n",
    "\n",
    "    payload = {\n",
    "        \"query\": query,\n",
    "        \"system_A\": {\"answer\": a.get(\"answer\") or \"\", \"products\": slim_products(a.get(\"products\") or [])},\n",
    "        \"system_B\": {\"answer\": b.get(\"answer\") or \"\", \"products\": slim_products(b.get(\"products\") or [])},\n",
    "        \"rubric\": {\n",
    "            \"faithfulness\": \"Answer must not contradict or invent facts not present in its own product list.\",\n",
    "            \"usefulness\": \"Clear, actionable, and matches the shopping intent.\",\n",
    "            \"format\": \"2–4 picks with id + short reason.\",\n",
    "        },\n",
    "    }\n",
    "\n",
    "    prompt = (\n",
    "        \"You are a strict evaluator for a shopping assistant.\\n\"\n",
    "        \"You will compare System A vs System B for the same user query.\\n\"\n",
    "        \"CRITICAL: Each system has its own PRODUCT LIST. Treat each list as authoritative for that system.\\n\"\n",
    "        \"Penalize hallucinations: mentioning prices/colors/ids not in that system's product list.\\n\"\n",
    "        \"Return ONLY valid JSON with this schema:\\n\"\n",
    "        \"{\\n\"\n",
    "        \"  \\\"winner\\\": \\\"A\\\"|\\\"B\\\"|\\\"TIE\\\",\\n\"\n",
    "        \"  \\\"scores\\\": {\\\"A\\\": {\\\"faithfulness\\\":0|1|2,\\\"usefulness\\\":0|1|2,\\\"format\\\":0|1|2},\\n\"\n",
    "        \"             \\\"B\\\": {\\\"faithfulness\\\":0|1|2,\\\"usefulness\\\":0|1|2,\\\"format\\\":0|1|2}},\\n\"\n",
    "        \"  \\\"reason\\\": \\\"short explanation\\\"\\n\"\n",
    "        \"}\\n\\n\"\n",
    "        f\"INPUT:\\n{json.dumps(payload, ensure_ascii=False)}\"\n",
    "    )\n",
    "\n",
    "    client = _get_openai_client_for_judge()\n",
    "    try:\n",
    "        resp = client.chat.completions.create(\n",
    "            model=LLM_MODEL,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0,\n",
    "            max_tokens=max_tokens,\n",
    "        )\n",
    "        txt = (resp.choices[0].message.content or \"\").strip()\n",
    "        # Cố gắng parse (best-effort)\n",
    "        data = json.loads(txt)\n",
    "        data[\"enabled\"] = True\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        return {\"enabled\": True, \"winner\": \"TIE\", \"reason\": f\"Lỗi judge: {type(e).__name__}: {e}\"}\n",
    "\n",
    "\n",
    "print({\"llm_judge_enabled\": _llm_judge_enabled(), \"LLM_BASE_URL\": LLM_BASE_URL or \"(default)\", \"LLM_MODEL\": LLM_MODEL or \"(unset)\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a538645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'API_BASE_A': 'http://127.0.0.1:8081', 'API_BASE_B': '(not set)'}\n",
      "A/B is disabled because API_BASE_B is not set.\n",
      "To enable A/B, set environment variables:\n",
      "- API_BASE_A=http://127.0.0.1:8081 (or your A server)\n",
      "- API_BASE_B=http://127.0.0.1:8082 (or your B server)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# T.3) Đánh giá A/B + báo cáo tỷ lệ thắng\n",
    "\n",
    "\n",
    "def call_chat_against_base(api_base: str, query: str, top_k: int = 5, filters: Optional[dict] = None, messages: Optional[list] = None) -> dict:\n",
    "    api_base = (api_base or \"\").rstrip(\"/\")\n",
    "    if not api_base:\n",
    "        return {\"status\": 0, \"latency_ms\": 0.0, \"error\": \"missing api_base\", \"response\": {}}\n",
    "\n",
    "    payload: Dict[str, Any] = {\"query\": query, \"top_k\": int(top_k)}\n",
    "    if filters:\n",
    "        payload[\"filters\"] = filters\n",
    "    if messages:\n",
    "        payload[\"messages\"] = messages\n",
    "\n",
    "    # Dùng lại logic _request_json, nhưng truyền base URL tường minh\n",
    "    status, data, latency_ms, err = _request_json(\"POST\", f\"{api_base}/chat\", payload)\n",
    "    return {\"status\": status, \"latency_ms\": latency_ms, \"error\": err, \"response\": data}\n",
    "\n",
    "\n",
    "def run_eval_on_base(api_base: str, testset: List[TestCase]) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    iterator = tqdm(testset, desc=f\"Đánh giá {api_base}\") if tqdm else testset\n",
    "    for tc in iterator:\n",
    "        res = call_chat_against_base(api_base, tc.query, top_k=tc.top_k)\n",
    "        resp = res.get(\"response\") or {}\n",
    "        rows.append(\n",
    "            {\n",
    "                \"name\": tc.name,\n",
    "                \"query\": tc.query,\n",
    "                \"status\": res.get(\"status\"),\n",
    "                \"latency_ms\": float(res.get(\"latency_ms\") or 0.0),\n",
    "                \"error\": res.get(\"error\"),\n",
    "                \"answer\": resp.get(\"answer\"),\n",
    "                \"products\": resp.get(\"products\") or [],\n",
    "                \"sources\": resp.get(\"sources\") or [],\n",
    "                \"expected_constraints\": tc.expected_constraints,\n",
    "            }\n",
    "        )\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def ab_winrate_rule_based(df_a: pd.DataFrame, df_b: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"So sánh A vs B bằng rubric_total (theo luật).\"\"\"\n",
    "    a_sc = score_df_rule_based(df_a).set_index(\"name\")\n",
    "    b_sc = score_df_rule_based(df_b).set_index(\"name\")\n",
    "\n",
    "    names = sorted(set(a_sc.index) & set(b_sc.index))\n",
    "    rows = []\n",
    "    for n in names:\n",
    "        a = a_sc.loc[n].to_dict()\n",
    "        b = b_sc.loc[n].to_dict()\n",
    "        a_total = float(a.get(\"rubric_total\") or 0)\n",
    "        b_total = float(b.get(\"rubric_total\") or 0)\n",
    "        if a_total > b_total:\n",
    "            winner = \"A\"\n",
    "        elif b_total > a_total:\n",
    "            winner = \"B\"\n",
    "        else:\n",
    "            winner = \"TIE\"\n",
    "        rows.append({\"name\": n, \"winner_rule\": winner, \"A_total\": a_total, \"B_total\": b_total})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def ab_winrate_llm_judge(df_a: pd.DataFrame, df_b: pd.DataFrame, max_cases: int = 30) -> pd.DataFrame:\n",
    "    \"\"\"So sánh A vs B bằng LLM judge (tuỳ chọn).\"\"\"\n",
    "    names = sorted(set(df_a[\"name\"]) & set(df_b[\"name\"]))\n",
    "    names = names[: max_cases]\n",
    "\n",
    "    rows = []\n",
    "    for n in (tqdm(names, desc=\"LLM judge A/B\") if tqdm else names):\n",
    "        ra = df_a[df_a[\"name\"] == n].iloc[0].to_dict()\n",
    "        rb = df_b[df_b[\"name\"] == n].iloc[0].to_dict()\n",
    "\n",
    "        out = llm_judge_pairwise(\n",
    "            query=ra.get(\"query\") or \"\",\n",
    "            a={\"answer\": ra.get(\"answer\"), \"products\": ra.get(\"products\")},\n",
    "            b={\"answer\": rb.get(\"answer\"), \"products\": rb.get(\"products\")},\n",
    "        )\n",
    "\n",
    "        rows.append({\"name\": n, **out})\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def summarize_winrate(win_df: pd.DataFrame, winner_col: str) -> Dict[str, Any]:\n",
    "    if win_df is None or len(win_df) == 0:\n",
    "        return {\"n\": 0}\n",
    "    counts = win_df[winner_col].value_counts(dropna=False).to_dict()\n",
    "    n = int(len(win_df))\n",
    "    return {\n",
    "        \"n\": n,\n",
    "        \"A_wins\": int(counts.get(\"A\", 0)),\n",
    "        \"B_wins\": int(counts.get(\"B\", 0)),\n",
    "        \"ties\": int(counts.get(\"TIE\", 0)),\n",
    "        \"A_win_rate\": float(counts.get(\"A\", 0) / max(1, n)),\n",
    "        \"B_win_rate\": float(counts.get(\"B\", 0) / max(1, n)),\n",
    "    }\n",
    "\n",
    "\n",
    "print({\"API_BASE_A\": API_BASE_A, \"API_BASE_B\": API_BASE_B or \"(not set)\"})\n",
    "\n",
    "# Chỉ chạy A/B khi có API_BASE_B\n",
    "if API_BASE_B:\n",
    "    DF_A = run_eval_on_base(API_BASE_A, TESTSET)\n",
    "    DF_B = run_eval_on_base(API_BASE_B, TESTSET)\n",
    "\n",
    "    WIN_RULE = ab_winrate_rule_based(DF_A, DF_B)\n",
    "    print(\"Tóm tắt tỷ lệ thắng (theo luật):\")\n",
    "    print(json.dumps(summarize_winrate(WIN_RULE, \"winner_rule\"), ensure_ascii=False, indent=2))\n",
    "    display(WIN_RULE)\n",
    "\n",
    "    # (Tuỳ chọn) Tỷ lệ thắng theo LLM judge\n",
    "    if _llm_judge_enabled():\n",
    "        WIN_JUDGE = ab_winrate_llm_judge(DF_A, DF_B, max_cases=len(TESTSET))\n",
    "        # Chuẩn hoá trường winner nếu bị thiếu\n",
    "        if \"winner\" in WIN_JUDGE.columns:\n",
    "            WIN_JUDGE[\"winner\"] = WIN_JUDGE[\"winner\"].fillna(\"TIE\")\n",
    "        print(\"Tóm tắt tỷ lệ thắng (LLM judge):\")\n",
    "        print(json.dumps(summarize_winrate(WIN_JUDGE, \"winner\"), ensure_ascii=False, indent=2))\n",
    "        display(WIN_JUDGE[[c for c in [\"name\", \"winner\", \"reason\"] if c in WIN_JUDGE.columns]])\n",
    "\n",
    "        # Lưu artifacts cho judge\n",
    "        (ARTIFACTS_DIR / \"ab_llm_judge.jsonl\").write_text(\n",
    "            \"\\n\".join(json.dumps(r, ensure_ascii=False) for r in WIN_JUDGE.to_dict(orient=\"records\")),\n",
    "            encoding=\"utf-8\",\n",
    "        )\n",
    "\n",
    "    # Lưu artifacts A/B\n",
    "    (ARTIFACTS_DIR / \"ab_rule_winrate.csv\").write_text(WIN_RULE.to_csv(index=False), encoding=\"utf-8\")\n",
    "    DF_A.to_csv(OUTPUTS_DIR / \"eval_text_A.csv\", index=False, encoding=\"utf-8\")\n",
    "    DF_B.to_csv(OUTPUTS_DIR / \"eval_text_B.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "    print(\"Đã lưu artifacts A/B vào outputs/ và artifacts/\")\n",
    "else:\n",
    "    print(\n",
    "        \"A/B đang tắt vì chưa đặt API_BASE_B.\\n\"\n",
    "        \"Để bật A/B, hãy đặt các biến môi trường:\\n\"\n",
    "        \"- API_BASE_A=http://127.0.0.1:8081 (hoặc server A của bạn)\\n\"\n",
    "        \"- API_BASE_B=http://127.0.0.1:8082 (hoặc server B của bạn)\\n\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
