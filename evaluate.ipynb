{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e87d41e",
   "metadata": {},
   "source": [
    "# Đánh giá hệ thống Chatbot (Fashion RAG)\n",
    "\n",
    "Notebook này đánh giá chatbot của bạn theo 5 nhóm chính:\n",
    "\n",
    "1) **Retrieval/RAG** (khi có nhãn *gold*): Hit@K, Recall@K, MRR, nDCG@K.\n",
    "2) **Task correctness (không cần reference)**: mức **tuân thủ ràng buộc** (budget, màu, usage/occasion, gender, articleType).\n",
    "3) **Answer faithfulness/groundedness**: câu trả lời có “bịa” ngoài danh sách `products` trả về hay không (heuristic).\n",
    "4) **Safety** (heuristic): phát hiện rò rỉ PII (email/phone/CC) và nội dung nhạy cảm theo regex.\n",
    "5) **Hiệu năng**: latency p50/p90/p95, error-rate, empty-result rate.\n",
    "\n",
    "> Lưu ý: API hiện **English-only** (trong `app/main.py`). Notebook có kiểm thử hành vi từ chối với query tiếng Việt.\n",
    "\n",
    "---\n",
    "\n",
    "## Các độ đo gợi ý (tóm tắt)\n",
    "\n",
    "### Retrieval / RAG\n",
    "- **Hit@K**: có ít nhất 1 tài liệu đúng trong top-K.\n",
    "- **Recall@K**: $\\frac{|\\text{relevant} \\cap \\text{topK}|}{|\\text{relevant}|}$.\n",
    "- **MRR**: $\\text{MRR} = \\frac{1}{N}\\sum_i \\frac{1}{\\text{rank}_i}$ (rank của kết quả đúng đầu tiên).\n",
    "- **nDCG@K**: đo chất lượng thứ hạng; với relevance nhị phân, DCG@K = $\\sum_{j=1..K} \\frac{rel_j}{\\log_2(j+1)}$.\n",
    "\n",
    "### Task / Constraint adherence\n",
    "- **Budget adherence**: mọi item trả về có price nằm trong [$min$, $max$] (nếu có price).\n",
    "- **Color/Usage/Gender/Type adherence**: tỉ lệ item khớp ràng buộc.\n",
    "\n",
    "### Hiệu năng\n",
    "- **Latency p50/p95**, **Error rate**, **Empty products rate**.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3638da85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifacts: D:\\Study\\CS311\\CS311\\artifacts\n",
      "Outputs: D:\\Study\\CS311\\CS311\\outputs\n"
     ]
    }
   ],
   "source": [
    "# 1) Cài đặt & import thư viện\n",
    "# Notebook ưu tiên chạy được với requirements.txt hiện có.\n",
    "# Một số thư viện (tqdm, matplotlib, seaborn, rouge_score, sacrebleu, bert_score, tiktoken, jsonschema)\n",
    "# sẽ được import theo kiểu optional.\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import hashlib\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Optional imports\n",
    "try:\n",
    "    from tqdm.auto import tqdm\n",
    "except Exception:\n",
    "    tqdm = None\n",
    "\n",
    "try:\n",
    "    import numpy as np\n",
    "except Exception:\n",
    "    np = None\n",
    "\n",
    "# Optional plotting\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "except Exception:\n",
    "    plt = None\n",
    "\n",
    "ARTIFACTS_DIR = Path(\"artifacts\")\n",
    "OUTPUTS_DIR = Path(\"outputs\")\n",
    "ARTIFACTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUTPUTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Artifacts:\", ARTIFACTS_DIR.resolve())\n",
    "print(\"Outputs:\", OUTPUTS_DIR.resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31a5497e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"api_base\": \"http://127.0.0.1:8081\",\n",
      "  \"timeout_s\": 30.0,\n",
      "  \"max_retries\": 2,\n",
      "  \"top_k_default\": 5,\n",
      "  \"timestamp\": \"2026-01-14 09:19:58\"\n",
      "}\n",
      "/health {'status': 200, 'latency_ms': 6.08, 'data': {'status': 'ok'}, 'err': None}\n"
     ]
    }
   ],
   "source": [
    "# 2) Khai báo cấu hình thí nghiệm\n",
    "\n",
    "API_BASE = os.getenv(\"API_BASE\", \"http://127.0.0.1:8081\").rstrip(\"/\")\n",
    "TIMEOUT_S = float(os.getenv(\"EVAL_TIMEOUT_S\", \"30\"))\n",
    "MAX_RETRIES = int(os.getenv(\"EVAL_MAX_RETRIES\", \"2\"))\n",
    "TOP_K_DEFAULT = int(os.getenv(\"EVAL_TOP_K\", \"5\"))\n",
    "\n",
    "CONFIG = {\n",
    "    \"api_base\": API_BASE,\n",
    "    \"timeout_s\": TIMEOUT_S,\n",
    "    \"max_retries\": MAX_RETRIES,\n",
    "    \"top_k_default\": TOP_K_DEFAULT,\n",
    "    \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "}\n",
    "\n",
    "(ARTIFACTS_DIR / \"eval_config.json\").write_text(json.dumps(CONFIG, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "print(json.dumps(CONFIG, ensure_ascii=False, indent=2))\n",
    "\n",
    "\n",
    "def _request_json(method: str, url: str, payload: Optional[dict] = None) -> Tuple[int, dict, float, Optional[str]]:\n",
    "    \"\"\"HTTP helper with retries.\n",
    "\n",
    "    Returns: (status_code, json_or_error, latency_ms, error_text)\n",
    "    \"\"\"\n",
    "    last_err = None\n",
    "    for attempt in range(MAX_RETRIES + 1):\n",
    "        t0 = time.perf_counter()\n",
    "        try:\n",
    "            resp = requests.request(\n",
    "                method=method,\n",
    "                url=url,\n",
    "                json=payload,\n",
    "                timeout=TIMEOUT_S,\n",
    "            )\n",
    "            latency_ms = (time.perf_counter() - t0) * 1000\n",
    "            try:\n",
    "                data = resp.json()\n",
    "            except Exception:\n",
    "                data = {\"_raw\": resp.text}\n",
    "            if 200 <= resp.status_code < 300:\n",
    "                return resp.status_code, data, latency_ms, None\n",
    "            last_err = f\"HTTP {resp.status_code}: {data}\"\n",
    "            # retry on 5xx\n",
    "            if resp.status_code >= 500 and attempt < MAX_RETRIES:\n",
    "                time.sleep(0.5 * (attempt + 1))\n",
    "                continue\n",
    "            return resp.status_code, data, latency_ms, last_err\n",
    "        except Exception as e:\n",
    "            latency_ms = (time.perf_counter() - t0) * 1000\n",
    "            last_err = f\"{type(e).__name__}: {e}\"\n",
    "            if attempt < MAX_RETRIES:\n",
    "                time.sleep(0.5 * (attempt + 1))\n",
    "                continue\n",
    "            return 0, {}, latency_ms, last_err\n",
    "\n",
    "\n",
    "def healthcheck() -> bool:\n",
    "    status, data, ms, err = _request_json(\"GET\", f\"{API_BASE}/health\")\n",
    "    print(\"/health\", {\"status\": status, \"latency_ms\": round(ms, 2), \"data\": data, \"err\": err})\n",
    "    return status == 200\n",
    "\n",
    "\n",
    "_healthy = healthcheck()\n",
    "if not _healthy:\n",
    "    print(\n",
    "        \"\\n[HINT] API chưa chạy hoặc sai API_BASE.\\n\"\n",
    "        \"- Nếu chạy bằng docker compose: mở http://127.0.0.1:8081/docs\\n\"\n",
    "        \"- Nếu chạy local uvicorn: kiểm tra port và biến API_BASE\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42e57e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 test cases\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>query</th>\n",
       "      <th>expected_ids</th>\n",
       "      <th>expected_constraints</th>\n",
       "      <th>should_reject</th>\n",
       "      <th>top_k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>basic_men_shoes_budget</td>\n",
       "      <td>men black sneakers under $80</td>\n",
       "      <td>None</td>\n",
       "      <td>{'gender': 'Men', 'color': 'Black', 'max_price...</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>formal_office</td>\n",
       "      <td>women formal office outfit under $100</td>\n",
       "      <td>None</td>\n",
       "      <td>{'usage': 'Formal', 'max_price': 100}</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>color_strict</td>\n",
       "      <td>women red dress</td>\n",
       "      <td>None</td>\n",
       "      <td>{'color': 'Red'}</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>type_tshirts</td>\n",
       "      <td>men white t-shirt</td>\n",
       "      <td>None</td>\n",
       "      <td>{'articleType': 'Tshirts', 'color': 'White', '...</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>reject_vietnamese</td>\n",
       "      <td>Tôi muốn mua áo sơ mi trắng đi làm dưới 40 đô</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     name                                          query  \\\n",
       "0  basic_men_shoes_budget                   men black sneakers under $80   \n",
       "1           formal_office          women formal office outfit under $100   \n",
       "2            color_strict                                women red dress   \n",
       "3            type_tshirts                              men white t-shirt   \n",
       "4       reject_vietnamese  Tôi muốn mua áo sơ mi trắng đi làm dưới 40 đô   \n",
       "\n",
       "  expected_ids                               expected_constraints  \\\n",
       "0         None  {'gender': 'Men', 'color': 'Black', 'max_price...   \n",
       "1         None              {'usage': 'Formal', 'max_price': 100}   \n",
       "2         None                                   {'color': 'Red'}   \n",
       "3         None  {'articleType': 'Tshirts', 'color': 'White', '...   \n",
       "4         None                                               None   \n",
       "\n",
       "   should_reject  top_k  \n",
       "0          False      5  \n",
       "1          False      5  \n",
       "2          False      5  \n",
       "3          False      5  \n",
       "4           True      5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3) Chuẩn hoá schema dữ liệu test & loader (đơn giản)\n",
    "\n",
    "# Trong project này, endpoint /chat nhận:\n",
    "# { query: str, top_k: int, filters?: dict, messages?: [{role,content}], max_tokens?: int, temperature?: float }\n",
    "# Trả về: { answer: str, products: [...], sources: [...] }\n",
    "\n",
    "@dataclass\n",
    "class TestCase:\n",
    "    name: str\n",
    "    query: str\n",
    "    expected_ids: Optional[List[str]] = None  # nếu bạn có nhãn product id đúng\n",
    "    expected_constraints: Optional[Dict[str, Any]] = None\n",
    "    should_reject: bool = False\n",
    "    top_k: int = TOP_K_DEFAULT\n",
    "\n",
    "\n",
    "def default_testset() -> List[TestCase]:\n",
    "    # NOTE: API English-only, nên query nên là tiếng Anh.\n",
    "    # expected_ids: bạn có thể điền sau (sau khi ingest xong) để tính retrieval metrics.\n",
    "    return [\n",
    "        TestCase(\n",
    "            name=\"basic_men_shoes_budget\",\n",
    "            query=\"men black sneakers under $80\",\n",
    "            expected_constraints={\"gender\": \"Men\", \"color\": \"Black\", \"max_price\": 80},\n",
    "        ),\n",
    "        TestCase(\n",
    "            name=\"formal_office\",\n",
    "            query=\"women formal office outfit under $100\",\n",
    "            expected_constraints={\"usage\": \"Formal\", \"max_price\": 100},\n",
    "        ),\n",
    "        TestCase(\n",
    "            name=\"color_strict\",\n",
    "            query=\"women red dress\",\n",
    "            expected_constraints={\"color\": \"Red\"},\n",
    "        ),\n",
    "        TestCase(\n",
    "            name=\"type_tshirts\",\n",
    "            query=\"men white t-shirt\",\n",
    "            expected_constraints={\"articleType\": \"Tshirts\", \"color\": \"White\", \"gender\": \"Men\"},\n",
    "        ),\n",
    "        # Kiểm thử English-only: tiếng Việt có dấu sẽ bị từ chối\n",
    "        TestCase(\n",
    "            name=\"reject_vietnamese\",\n",
    "            query=\"Tôi muốn mua áo sơ mi trắng đi làm dưới 40 đô\",\n",
    "            should_reject=True,\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "\n",
    "TESTSET = default_testset()\n",
    "print(f\"Loaded {len(TESTSET)} test cases\")\n",
    "pd.DataFrame([t.__dict__ for t in TESTSET])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62f4658e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>query</th>\n",
       "      <th>should_reject</th>\n",
       "      <th>expected_ids</th>\n",
       "      <th>expected_constraints</th>\n",
       "      <th>status</th>\n",
       "      <th>latency_ms</th>\n",
       "      <th>error</th>\n",
       "      <th>cached</th>\n",
       "      <th>answer</th>\n",
       "      <th>products</th>\n",
       "      <th>sources</th>\n",
       "      <th>n_products</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>basic_men_shoes_budget</td>\n",
       "      <td>men black sneakers under $80</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>{'gender': 'Men', 'color': 'Black', 'max_price...</td>\n",
       "      <td>200</td>\n",
       "      <td>531.8409</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>Quick summary: Here are the closest matches fo...</td>\n",
       "      <td>[{'id': '24626', 'name': 'Converse Men Black R...</td>\n",
       "      <td>[{'id': '24626', 'text': 'Converse Men Black R...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>formal_office</td>\n",
       "      <td>women formal office outfit under $100</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>{'usage': 'Formal', 'max_price': 100}</td>\n",
       "      <td>200</td>\n",
       "      <td>1042.7743</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>Quick summary: Here are the closest matches fo...</td>\n",
       "      <td>[{'id': '57116', 'name': 'Elle Women White Sem...</td>\n",
       "      <td>[{'id': '57116', 'text': 'Elle Women White Sem...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>color_strict</td>\n",
       "      <td>women red dress</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>{'color': 'Red'}</td>\n",
       "      <td>200</td>\n",
       "      <td>43.0992</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>Quick summary: Here are the closest matches fo...</td>\n",
       "      <td>[{'id': '45777', 'name': 'Remanika Women Red D...</td>\n",
       "      <td>[{'id': '45777', 'text': 'Remanika Women Red D...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>type_tshirts</td>\n",
       "      <td>men white t-shirt</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>{'articleType': 'Tshirts', 'color': 'White', '...</td>\n",
       "      <td>200</td>\n",
       "      <td>39.2038</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>Quick summary: Here are the closest matches fo...</td>\n",
       "      <td>[{'id': '2853', 'name': 'Mr.Men Printed White ...</td>\n",
       "      <td>[{'id': '2853', 'text': 'Mr.Men Printed White ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>reject_vietnamese</td>\n",
       "      <td>Tôi muốn mua áo sơ mi trắng đi làm dưới 40 đô</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>3.6427</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>English only: please rephrase your request in ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     name                                          query  \\\n",
       "0  basic_men_shoes_budget                   men black sneakers under $80   \n",
       "1           formal_office          women formal office outfit under $100   \n",
       "2            color_strict                                women red dress   \n",
       "3            type_tshirts                              men white t-shirt   \n",
       "4       reject_vietnamese  Tôi muốn mua áo sơ mi trắng đi làm dưới 40 đô   \n",
       "\n",
       "   should_reject expected_ids  \\\n",
       "0          False         None   \n",
       "1          False         None   \n",
       "2          False         None   \n",
       "3          False         None   \n",
       "4           True         None   \n",
       "\n",
       "                                expected_constraints  status  latency_ms  \\\n",
       "0  {'gender': 'Men', 'color': 'Black', 'max_price...     200    531.8409   \n",
       "1              {'usage': 'Formal', 'max_price': 100}     200   1042.7743   \n",
       "2                                   {'color': 'Red'}     200     43.0992   \n",
       "3  {'articleType': 'Tshirts', 'color': 'White', '...     200     39.2038   \n",
       "4                                               None     200      3.6427   \n",
       "\n",
       "  error  cached                                             answer  \\\n",
       "0  None    True  Quick summary: Here are the closest matches fo...   \n",
       "1  None    True  Quick summary: Here are the closest matches fo...   \n",
       "2  None    True  Quick summary: Here are the closest matches fo...   \n",
       "3  None    True  Quick summary: Here are the closest matches fo...   \n",
       "4  None    True  English only: please rephrase your request in ...   \n",
       "\n",
       "                                            products  \\\n",
       "0  [{'id': '24626', 'name': 'Converse Men Black R...   \n",
       "1  [{'id': '57116', 'name': 'Elle Women White Sem...   \n",
       "2  [{'id': '45777', 'name': 'Remanika Women Red D...   \n",
       "3  [{'id': '2853', 'name': 'Mr.Men Printed White ...   \n",
       "4                                                 []   \n",
       "\n",
       "                                             sources  n_products  \n",
       "0  [{'id': '24626', 'text': 'Converse Men Black R...           5  \n",
       "1  [{'id': '57116', 'text': 'Elle Women White Sem...           4  \n",
       "2  [{'id': '45777', 'text': 'Remanika Women Red D...           5  \n",
       "3  [{'id': '2853', 'text': 'Mr.Men Printed White ...           5  \n",
       "4                                                 []           0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4) Chạy chatbot hàng loạt (batch) + logging\n",
    "\n",
    "CACHE_PATH = ARTIFACTS_DIR / \"eval_cache.json\"\n",
    "try:\n",
    "    _CACHE = json.loads(CACHE_PATH.read_text(encoding=\"utf-8\")) if CACHE_PATH.exists() else {}\n",
    "except Exception:\n",
    "    _CACHE = {}\n",
    "\n",
    "\n",
    "def _hash_payload(payload: dict) -> str:\n",
    "    s = json.dumps(payload, sort_keys=True, ensure_ascii=False)\n",
    "    return hashlib.sha256(s.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "\n",
    "def call_chat(query: str, top_k: int = 5, filters: Optional[dict] = None, messages: Optional[list] = None) -> dict:\n",
    "    payload: Dict[str, Any] = {\n",
    "        \"query\": query,\n",
    "        \"top_k\": int(top_k),\n",
    "    }\n",
    "    if filters:\n",
    "        payload[\"filters\"] = filters\n",
    "    if messages:\n",
    "        payload[\"messages\"] = messages\n",
    "\n",
    "    key = _hash_payload(payload)\n",
    "    if key in _CACHE:\n",
    "        out = dict(_CACHE[key])\n",
    "        out[\"_cached\"] = True\n",
    "        return out\n",
    "\n",
    "    status, data, latency_ms, err = _request_json(\"POST\", f\"{API_BASE}/chat\", payload)\n",
    "    out = {\n",
    "        \"status\": status,\n",
    "        \"latency_ms\": latency_ms,\n",
    "        \"error\": err,\n",
    "        \"response\": data,\n",
    "        \"_cached\": False,\n",
    "    }\n",
    "    _CACHE[key] = out\n",
    "    return out\n",
    "\n",
    "\n",
    "def run_eval(testset: List[TestCase]) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    iterator = tqdm(testset, desc=\"Evaluating\") if tqdm else testset\n",
    "    for tc in iterator:\n",
    "        res = call_chat(tc.query, top_k=tc.top_k)\n",
    "        resp = res.get(\"response\") or {}\n",
    "        products = resp.get(\"products\") or []\n",
    "        sources = resp.get(\"sources\") or []\n",
    "        answer = resp.get(\"answer\")\n",
    "        rows.append(\n",
    "            {\n",
    "                \"name\": tc.name,\n",
    "                \"query\": tc.query,\n",
    "                \"should_reject\": bool(tc.should_reject),\n",
    "                \"expected_ids\": tc.expected_ids,\n",
    "                \"expected_constraints\": tc.expected_constraints,\n",
    "                \"status\": res.get(\"status\"),\n",
    "                \"latency_ms\": float(res.get(\"latency_ms\") or 0.0),\n",
    "                \"error\": res.get(\"error\"),\n",
    "                \"cached\": bool(res.get(\"_cached\")),\n",
    "                \"answer\": answer,\n",
    "                \"products\": products,\n",
    "                \"sources\": sources,\n",
    "                \"n_products\": len(products) if isinstance(products, list) else 0,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    # Persist cache and raw results\n",
    "    CACHE_PATH.write_text(json.dumps(_CACHE, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "    (ARTIFACTS_DIR / \"predictions.jsonl\").write_text(\n",
    "        \"\\n\".join(json.dumps(r, ensure_ascii=False) for r in rows),\n",
    "        encoding=\"utf-8\",\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "DF = run_eval(TESTSET)\n",
    "DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4832947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"n_cases\": 5,\n",
      "  \"error_rate\": 0.0,\n",
      "  \"empty_products_rate\": 0.2,\n",
      "  \"latency_p50_ms\": 43.099200000142446,\n",
      "  \"latency_p90_ms\": 838.4009399997012,\n",
      "  \"latency_p95_ms\": 940.5876199998601,\n",
      "  \"latency_mean_ms\": 332.11217999923974,\n",
      "  \"english_only_reject_accuracy\": 1.0,\n",
      "  \"constraint_pass_rate\": 0.8,\n",
      "  \"faithfulness_pass_rate\": 0.8\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>status</th>\n",
       "      <th>latency_ms</th>\n",
       "      <th>n_products</th>\n",
       "      <th>rejected_english_only</th>\n",
       "      <th>faith_mentioned_ids</th>\n",
       "      <th>faith_extra_ids_not_in_products</th>\n",
       "      <th>faith_money_mentions</th>\n",
       "      <th>faith_money_matches_products</th>\n",
       "      <th>faith_faithful</th>\n",
       "      <th>...</th>\n",
       "      <th>hit@1</th>\n",
       "      <th>recall@1</th>\n",
       "      <th>ndcg@1</th>\n",
       "      <th>hit@3</th>\n",
       "      <th>recall@3</th>\n",
       "      <th>ndcg@3</th>\n",
       "      <th>hit@5</th>\n",
       "      <th>recall@5</th>\n",
       "      <th>ndcg@5</th>\n",
       "      <th>mrr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>basic_men_shoes_budget</td>\n",
       "      <td>200</td>\n",
       "      <td>531.8409</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>[24626, 3585, 6344, 6652]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[80.0, 45.0, 25.0, 80.0, 61.0]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>formal_office</td>\n",
       "      <td>200</td>\n",
       "      <td>1042.7743</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>[12514, 2880, 32407, 57116]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[100.0, 16.0, 5.0, 16.0, 87.0]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>color_strict</td>\n",
       "      <td>200</td>\n",
       "      <td>43.0992</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>[33199, 43680, 45777, 57057]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[110.0, 150.0, 38.0, 27.0]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>type_tshirts</td>\n",
       "      <td>200</td>\n",
       "      <td>39.2038</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>[23945, 2853, 8271, 8274]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[140.0, 111.0, 103.0, 188.0]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>reject_vietnamese</td>\n",
       "      <td>200</td>\n",
       "      <td>3.6427</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     name  status  latency_ms  n_products  \\\n",
       "0  basic_men_shoes_budget     200    531.8409           5   \n",
       "1           formal_office     200   1042.7743           4   \n",
       "2            color_strict     200     43.0992           5   \n",
       "3            type_tshirts     200     39.2038           5   \n",
       "4       reject_vietnamese     200      3.6427           0   \n",
       "\n",
       "   rejected_english_only           faith_mentioned_ids  \\\n",
       "0                  False     [24626, 3585, 6344, 6652]   \n",
       "1                  False   [12514, 2880, 32407, 57116]   \n",
       "2                  False  [33199, 43680, 45777, 57057]   \n",
       "3                  False     [23945, 2853, 8271, 8274]   \n",
       "4                   True                            []   \n",
       "\n",
       "  faith_extra_ids_not_in_products            faith_money_mentions  \\\n",
       "0                              []  [80.0, 45.0, 25.0, 80.0, 61.0]   \n",
       "1                              []  [100.0, 16.0, 5.0, 16.0, 87.0]   \n",
       "2                              []      [110.0, 150.0, 38.0, 27.0]   \n",
       "3                              []    [140.0, 111.0, 103.0, 188.0]   \n",
       "4                              []                              []   \n",
       "\n",
       "   faith_money_matches_products  faith_faithful  ...  hit@1 recall@1 ndcg@1  \\\n",
       "0                          True            True  ...    NaN      NaN    NaN   \n",
       "1                         False           False  ...    NaN      NaN    NaN   \n",
       "2                          True            True  ...    NaN      NaN    NaN   \n",
       "3                          True            True  ...    NaN      NaN    NaN   \n",
       "4                          True            True  ...    NaN      NaN    NaN   \n",
       "\n",
       "  hit@3 recall@3 ndcg@3  hit@5  recall@5  ndcg@5  mrr  \n",
       "0   NaN      NaN    NaN    NaN       NaN     NaN  NaN  \n",
       "1   NaN      NaN    NaN    NaN       NaN     NaN  NaN  \n",
       "2   NaN      NaN    NaN    NaN       NaN     NaN  NaN  \n",
       "3   NaN      NaN    NaN    NaN       NaN     NaN  NaN  \n",
       "4   NaN      NaN    NaN    NaN       NaN     NaN  NaN  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5) Metrics: retrieval + constraint adherence + English-only + hiệu năng\n",
    "\n",
    "def _safe_float(x: Any) -> Optional[float]:\n",
    "    try:\n",
    "        if x is None:\n",
    "            return None\n",
    "        return float(x)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def _normalize_str(x: Any) -> str:\n",
    "    return (\"\" if x is None else str(x)).strip()\n",
    "\n",
    "\n",
    "def _normalize_color(x: Any) -> str:\n",
    "    s = _normalize_str(x).lower()\n",
    "    s = re.sub(r\"[^a-z]+\", \"\", s)\n",
    "    if s == \"grey\":\n",
    "        return \"gray\"\n",
    "    return s\n",
    "\n",
    "\n",
    "def _normalize_article_type(x: Any) -> str:\n",
    "    s = _normalize_str(x).lower()\n",
    "    s = re.sub(r\"[^a-z0-9]+\", \"\", s)\n",
    "    return s\n",
    "\n",
    "\n",
    "def _extract_prices(products: list) -> List[float]:\n",
    "    out = []\n",
    "    for p in products or []:\n",
    "        if not isinstance(p, dict):\n",
    "            continue\n",
    "        v = _safe_float(p.get(\"price\"))\n",
    "        if v is None:\n",
    "            continue\n",
    "        if v >= 0:\n",
    "            out.append(v)\n",
    "    return out\n",
    "\n",
    "\n",
    "def _ids_from_products(products: list) -> List[str]:\n",
    "    out: List[str] = []\n",
    "    for p in products or []:\n",
    "        if isinstance(p, dict) and p.get(\"id\") is not None:\n",
    "            out.append(str(p.get(\"id\")))\n",
    "    return out\n",
    "\n",
    "\n",
    "def _ids_from_sources(sources: list) -> List[str]:\n",
    "    out: List[str] = []\n",
    "    for s in sources or []:\n",
    "        if isinstance(s, dict) and s.get(\"id\") is not None:\n",
    "            out.append(str(s.get(\"id\")))\n",
    "    return out\n",
    "\n",
    "\n",
    "def hit_at_k(pred_ids: List[str], gold_ids: List[str], k: int) -> float:\n",
    "    if not gold_ids:\n",
    "        return float(\"nan\")\n",
    "    topk = pred_ids[:k]\n",
    "    return 1.0 if any(pid in set(gold_ids) for pid in topk) else 0.0\n",
    "\n",
    "\n",
    "def recall_at_k(pred_ids: List[str], gold_ids: List[str], k: int) -> float:\n",
    "    if not gold_ids:\n",
    "        return float(\"nan\")\n",
    "    topk = pred_ids[:k]\n",
    "    g = set(gold_ids)\n",
    "    return len([pid for pid in topk if pid in g]) / max(1, len(g))\n",
    "\n",
    "\n",
    "def mrr(pred_ids: List[str], gold_ids: List[str]) -> float:\n",
    "    if not gold_ids:\n",
    "        return float(\"nan\")\n",
    "    g = set(gold_ids)\n",
    "    for i, pid in enumerate(pred_ids, start=1):\n",
    "        if pid in g:\n",
    "            return 1.0 / i\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def ndcg_at_k(pred_ids: List[str], gold_ids: List[str], k: int) -> float:\n",
    "    if not gold_ids:\n",
    "        return float(\"nan\")\n",
    "    g = set(gold_ids)\n",
    "\n",
    "    def dcg(ids: List[str]) -> float:\n",
    "        s = 0.0\n",
    "        for j, pid in enumerate(ids[:k], start=1):\n",
    "            rel = 1.0 if pid in g else 0.0\n",
    "            s += rel / math.log2(j + 1)\n",
    "        return s\n",
    "\n",
    "    ideal = [pid for pid in gold_ids][:k]\n",
    "    # If there are more gold than k, ideal DCG is k ones.\n",
    "    if len(ideal) < k:\n",
    "        ideal = ideal + [\"__non__\"] * (k - len(ideal))\n",
    "    denom = dcg(ideal)\n",
    "    if denom <= 0:\n",
    "        return 0.0\n",
    "    return dcg(pred_ids) / denom\n",
    "\n",
    "\n",
    "def english_only_rejected(answer: str, products: list, response_obj: dict) -> bool:\n",
    "    # /chat returns answer string; for /query it returns error field.\n",
    "    a = (answer or \"\").lower()\n",
    "    if \"english only\" in a:\n",
    "        return True\n",
    "    if isinstance(response_obj, dict) and \"error\" in response_obj:\n",
    "        if \"english\" in str(response_obj.get(\"error\") or \"\").lower():\n",
    "            return True\n",
    "    # Heuristic: reject if no products and message indicates english\n",
    "    if (not products) and (\"rephrase\" in a and \"english\" in a):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def constraint_checks(products: list, constraints: Optional[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "    \"\"\"Return a dict of constraint adherence checks.\n",
    "\n",
    "    We evaluate on returned `products` (UI cards) because in this project the answer is derived from them.\n",
    "    \"\"\"\n",
    "    constraints = constraints or {}\n",
    "    out: Dict[str, Any] = {}\n",
    "\n",
    "    if not products:\n",
    "        out[\"has_products\"] = False\n",
    "        # If user expects constraints but there are no products, treat as fail.\n",
    "        out[\"constraint_pass\"] = False if constraints else True\n",
    "        return out\n",
    "\n",
    "    out[\"has_products\"] = True\n",
    "\n",
    "    # --- Color ---\n",
    "    if \"color\" in constraints and constraints[\"color\"] is not None:\n",
    "        want = _normalize_color(constraints[\"color\"])\n",
    "        colors = [_normalize_color((p or {}).get(\"color\")) for p in products if isinstance(p, dict)]\n",
    "        # strict: all returned products must match\n",
    "        out[\"color_all_match\"] = all(c == want and c for c in colors)\n",
    "    else:\n",
    "        out[\"color_all_match\"] = None\n",
    "\n",
    "    # --- Usage ---\n",
    "    if \"usage\" in constraints and constraints[\"usage\"] is not None:\n",
    "        want = _normalize_str(constraints[\"usage\"]).lower()\n",
    "        usages = [_normalize_str((p or {}).get(\"usage\")).lower() for p in products if isinstance(p, dict)]\n",
    "        out[\"usage_all_match\"] = all(u == want and u for u in usages)\n",
    "    else:\n",
    "        out[\"usage_all_match\"] = None\n",
    "\n",
    "    # --- Gender ---\n",
    "    if \"gender\" in constraints and constraints[\"gender\"] is not None:\n",
    "        want = _normalize_str(constraints[\"gender\"]).lower()\n",
    "        genders = [_normalize_str((p or {}).get(\"gender\")).lower() for p in products if isinstance(p, dict)]\n",
    "        out[\"gender_all_match\"] = all(g == want and g for g in genders)\n",
    "    else:\n",
    "        out[\"gender_all_match\"] = None\n",
    "\n",
    "    # --- Article type ---\n",
    "    if \"articleType\" in constraints and constraints[\"articleType\"] is not None:\n",
    "        want = _normalize_article_type(constraints[\"articleType\"])\n",
    "        ats = [_normalize_article_type((p or {}).get(\"subcategory\") or (p or {}).get(\"category\") or (p or {}).get(\"articleType\")) for p in products if isinstance(p, dict)]\n",
    "        # NOTE: dataset stores articleType in metadata but API card currently doesn't include it.\n",
    "        # If missing, we can't reliably check.\n",
    "        out[\"type_all_match\"] = None if all(a == \"\" for a in ats) else all(a == want for a in ats if a)\n",
    "    else:\n",
    "        out[\"type_all_match\"] = None\n",
    "\n",
    "    # --- Budget ---\n",
    "    prices = _extract_prices(products)\n",
    "    min_p = _safe_float(constraints.get(\"min_price\"))\n",
    "    max_p = _safe_float(constraints.get(\"max_price\"))\n",
    "    if min_p is not None or max_p is not None:\n",
    "        if not prices:\n",
    "            out[\"budget_all_match\"] = False\n",
    "        else:\n",
    "            ok = True\n",
    "            for p in prices:\n",
    "                if min_p is not None and p < min_p - 1e-9:\n",
    "                    ok = False\n",
    "                if max_p is not None and p > max_p + 1e-9:\n",
    "                    ok = False\n",
    "            out[\"budget_all_match\"] = ok\n",
    "    else:\n",
    "        out[\"budget_all_match\"] = None\n",
    "\n",
    "    # Aggregate\n",
    "    bool_checks = [v for v in [out.get(\"color_all_match\"), out.get(\"usage_all_match\"), out.get(\"gender_all_match\"), out.get(\"budget_all_match\"), out.get(\"type_all_match\")] if isinstance(v, bool)]\n",
    "    out[\"constraint_pass\"] = all(bool_checks) if bool_checks else True\n",
    "    return out\n",
    "\n",
    "\n",
    "def faithfulness_heuristic(answer: str, products: list) -> Dict[str, Any]:\n",
    "    \"\"\"Heuristic groundedness checks.\n",
    "\n",
    "    This project builds answer deterministically from `products` in llm_client._answer_from_products,\n",
    "    so violations should be rare. Still, we check for:\n",
    "    - Mentioning IDs not in products\n",
    "    - Mentioning prices not in products (very heuristic)\n",
    "    \"\"\"\n",
    "    ans = answer or \"\"\n",
    "    pids = set(_ids_from_products(products))\n",
    "\n",
    "    # Extract tokens like \"(12345)\" or \" 12345 \" as ids.\n",
    "    mentioned = set(re.findall(r\"\\((\\d+)\\)\", ans))\n",
    "    extra_ids = sorted([x for x in mentioned if x not in pids])\n",
    "\n",
    "    # Extract $numbers in answer\n",
    "    money = [float(x) for x in re.findall(r\"\\$(\\d+(?:\\.\\d{1,2})?)\", ans)]\n",
    "    prices = set(round(p, 2) for p in _extract_prices(products))\n",
    "    # If answer mentions money but we have no product prices, flag.\n",
    "    money_ok = True\n",
    "    if money and not prices:\n",
    "        money_ok = False\n",
    "    else:\n",
    "        for m in money:\n",
    "            if round(m, 2) not in prices:\n",
    "                # allow small formatting differences (integers)\n",
    "                if round(m, 0) not in {round(p, 0) for p in prices}:\n",
    "                    money_ok = False\n",
    "\n",
    "    return {\n",
    "        \"mentioned_ids\": sorted(list(mentioned)),\n",
    "        \"extra_ids_not_in_products\": extra_ids,\n",
    "        \"money_mentions\": money,\n",
    "        \"money_matches_products\": money_ok,\n",
    "        \"faithful\": (len(extra_ids) == 0) and money_ok,\n",
    "    }\n",
    "\n",
    "\n",
    "def pii_safety_heuristic(text: str) -> Dict[str, Any]:\n",
    "    s = text or \"\"\n",
    "    email = re.findall(r\"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\", s)\n",
    "    phone = re.findall(r\"\\b(?:\\+?\\d{1,3}[-.\\s]?)?(?:\\(?\\d{2,4}\\)?[-.\\s]?)?\\d{3,4}[-.\\s]?\\d{3,4}\\b\", s)\n",
    "    cc = re.findall(r\"\\b(?:\\d[ -]*?){13,19}\\b\", s)\n",
    "\n",
    "    # Reduce false positives for CC: keep only sequences with >=13 digits\n",
    "    cc_clean = []\n",
    "    for c in cc:\n",
    "        digits = re.sub(r\"\\D\", \"\", c)\n",
    "        if len(digits) >= 13:\n",
    "            cc_clean.append(digits)\n",
    "\n",
    "    return {\n",
    "        \"email_found\": len(email) > 0,\n",
    "        \"phone_found\": len(phone) > 0,\n",
    "        \"cc_like_found\": len(cc_clean) > 0,\n",
    "        \"pii_violation\": (len(email) > 0) or (len(cc_clean) > 0),\n",
    "    }\n",
    "\n",
    "\n",
    "def compute_metrics(df: pd.DataFrame, k_values: List[int] = [1, 3, 5]) -> Tuple[pd.DataFrame, Dict[str, Any]]:\n",
    "    rows = []\n",
    "    for _, r in df.iterrows():\n",
    "        products = r.get(\"products\") or []\n",
    "        sources = r.get(\"sources\") or []\n",
    "        answer = r.get(\"answer\") or \"\"\n",
    "        resp_obj = r.get(\"response\") if \"response\" in df.columns else {}\n",
    "\n",
    "        pred_ids = _ids_from_sources(sources) or _ids_from_products(products)\n",
    "        gold = r.get(\"expected_ids\") or []\n",
    "        gold = [str(x) for x in gold] if isinstance(gold, list) else []\n",
    "\n",
    "        faith = faithfulness_heuristic(answer, products)\n",
    "        constraints = constraint_checks(products, r.get(\"expected_constraints\"))\n",
    "        rejected = english_only_rejected(answer, products, {})\n",
    "        pii = pii_safety_heuristic(answer)\n",
    "\n",
    "        row = {\n",
    "            \"name\": r.get(\"name\"),\n",
    "            \"status\": r.get(\"status\"),\n",
    "            \"latency_ms\": r.get(\"latency_ms\"),\n",
    "            \"n_products\": r.get(\"n_products\"),\n",
    "            \"rejected_english_only\": rejected,\n",
    "            **{f\"faith_{k}\": v for k, v in faith.items()},\n",
    "            **{f\"c_{k}\": v for k, v in constraints.items()},\n",
    "            **{f\"pii_{k}\": v for k, v in pii.items()},\n",
    "        }\n",
    "\n",
    "        for k in k_values:\n",
    "            row[f\"hit@{k}\"] = hit_at_k(pred_ids, gold, k) if gold else float(\"nan\")\n",
    "            row[f\"recall@{k}\"] = recall_at_k(pred_ids, gold, k) if gold else float(\"nan\")\n",
    "            row[f\"ndcg@{k}\"] = ndcg_at_k(pred_ids, gold, k) if gold else float(\"nan\")\n",
    "        row[\"mrr\"] = mrr(pred_ids, gold) if gold else float(\"nan\")\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "    mdf = pd.DataFrame(rows)\n",
    "\n",
    "    # Summary\n",
    "    summary: Dict[str, Any] = {}\n",
    "\n",
    "    # Basic operational\n",
    "    summary[\"n_cases\"] = int(len(df))\n",
    "    summary[\"error_rate\"] = float((df[\"status\"].fillna(0).astype(int) == 0).mean()) if len(df) else 0.0\n",
    "    summary[\"empty_products_rate\"] = float((df[\"n_products\"].fillna(0).astype(int) == 0).mean()) if len(df) else 0.0\n",
    "\n",
    "    lat = df[\"latency_ms\"].astype(float) if len(df) else pd.Series([], dtype=float)\n",
    "    if len(lat):\n",
    "        summary[\"latency_p50_ms\"] = float(lat.quantile(0.50))\n",
    "        summary[\"latency_p90_ms\"] = float(lat.quantile(0.90))\n",
    "        summary[\"latency_p95_ms\"] = float(lat.quantile(0.95))\n",
    "        summary[\"latency_mean_ms\"] = float(lat.mean())\n",
    "\n",
    "    # English-only behavior\n",
    "    if \"should_reject\" in df.columns:\n",
    "        want_reject = df[\"should_reject\"].astype(bool)\n",
    "        got_reject = mdf[\"rejected_english_only\"].astype(bool)\n",
    "        if want_reject.any():\n",
    "            summary[\"english_only_reject_accuracy\"] = float((got_reject[want_reject] == True).mean())\n",
    "\n",
    "    # Constraint\n",
    "    if \"c_constraint_pass\" in mdf.columns:\n",
    "        # Only count rows where constraints exist or has_products? We'll just average boolean where it's bool.\n",
    "        vals = mdf[\"c_constraint_pass\"].dropna()\n",
    "        if len(vals):\n",
    "            summary[\"constraint_pass_rate\"] = float(vals.astype(bool).mean())\n",
    "\n",
    "    # Faithfulness\n",
    "    vals = mdf[\"faith_faithful\"].dropna() if \"faith_faithful\" in mdf.columns else pd.Series([], dtype=bool)\n",
    "    if len(vals):\n",
    "        summary[\"faithfulness_pass_rate\"] = float(vals.astype(bool).mean())\n",
    "\n",
    "    # Retrieval metrics: average over rows that have gold\n",
    "    gold_mask = df[\"expected_ids\"].apply(lambda x: isinstance(x, list) and len(x) > 0)\n",
    "    if gold_mask.any():\n",
    "        for k in k_values:\n",
    "            summary[f\"hit@{k}\"] = float(mdf.loc[gold_mask, f\"hit@{k}\"].mean())\n",
    "            summary[f\"recall@{k}\"] = float(mdf.loc[gold_mask, f\"recall@{k}\"].mean())\n",
    "            summary[f\"ndcg@{k}\"] = float(mdf.loc[gold_mask, f\"ndcg@{k}\"].mean())\n",
    "        summary[\"mrr\"] = float(mdf.loc[gold_mask, \"mrr\"].mean())\n",
    "\n",
    "    return mdf, summary\n",
    "\n",
    "\n",
    "MDF, SUMMARY = compute_metrics(DF)\n",
    "print(json.dumps(SUMMARY, ensure_ascii=False, indent=2))\n",
    "MDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b9858b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:\n",
      "- D:\\Study\\CS311\\CS311\\outputs\\eval_results.csv\n",
      "- D:\\Study\\CS311\\CS311\\artifacts\\eval_summary.json\n"
     ]
    }
   ],
   "source": [
    "# 6) Báo cáo + lưu artifacts\n",
    "\n",
    "# Merge metrics back to main DF for convenience\n",
    "OUT = DF.merge(MDF, on=\"name\", how=\"left\", suffixes=(\"\", \"_m\"))\n",
    "\n",
    "csv_path = OUTPUTS_DIR / \"eval_results.csv\"\n",
    "OUT.to_csv(csv_path, index=False, encoding=\"utf-8\")\n",
    "(ARTIFACTS_DIR / \"eval_summary.json\").write_text(json.dumps(SUMMARY, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\"-\", csv_path.resolve())\n",
    "print(\"-\", (ARTIFACTS_DIR / \"eval_summary.json\").resolve())\n",
    "\n",
    "# Pretty display\n",
    "cols_show = [\n",
    "    \"name\",\n",
    "    \"status\",\n",
    "    \"latency_ms\",\n",
    "    \"n_products\",\n",
    "    \"should_reject\",\n",
    "    \"rejected_english_only\",\n",
    "    \"c_constraint_pass\",\n",
    "    \"faith_faithful\",\n",
    "]\n",
    "cols_show = [c for c in cols_show if c in OUT.columns]\n",
    "OUT[cols_show]\n",
    "\n",
    "\n",
    "# Optional: plot latency histogram\n",
    "if plt is not None and len(OUT):\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    plt.hist(OUT[\"latency_ms\"].astype(float), bins=20)\n",
    "    plt.title(\"Latency histogram (ms)\")\n",
    "    plt.xlabel(\"ms\")\n",
    "    plt.ylabel(\"count\")\n",
    "    plt.grid(True, alpha=0.2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b1de11",
   "metadata": {},
   "source": [
    "## Bổ sung: làm thế nào để có *gold labels* cho Retrieval metrics?\n",
    "\n",
    "Vì dataset `styles.csv` khá lớn, cách thực tế nhất là:\n",
    "\n",
    "1) Chạy vài query tiêu biểu.\n",
    "2) Nhìn top kết quả trong `products`/`sources`.\n",
    "3) Chọn 1–3 `product id` bạn xem là **đúng nhất** → điền vào `expected_ids` trong `TESTSET`.\n",
    "\n",
    "Sau đó rerun notebook để có **Hit@K / MRR / nDCG**.\n",
    "\n",
    "---\n",
    "\n",
    "## (Tuỳ chọn) Metrics theo reference answer (BLEU/ROUGE/BERTScore)\n",
    "\n",
    "Trong dự án hiện tại, câu trả lời `answer` được tạo “deterministic” từ `products` (để tránh hallucination), nên reference-answer metrics thường **không phản ánh đúng** chất lượng tìm kiếm.\n",
    "\n",
    "Nếu bạn có bộ `reference` (ví dụ: câu trả lời mẫu do người chấm viết), bạn có thể thêm cột `reference` vào test cases và cài thêm thư viện như `sacrebleu`, `rouge_score`, `bert_score` để tính.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f67c57f",
   "metadata": {},
   "source": [
    "## C) Đánh giá Image RAG (tìm kiếm bằng ảnh)\n",
    "\n",
    "Hệ của bạn có endpoint `POST /search/image/upload` (embed ảnh bằng OpenCLIP và truy vấn collection `products_image`).\n",
    "\n",
    "### Tư tưởng đánh giá “tối ưu” cho Image RAG\n",
    "\n",
    "1) **Self-retrieval**: lấy một ảnh từ dataset làm query → kết quả top-K có chứa **chính id của ảnh đó**.\n",
    "   - Đây là dạng *gold label* rẻ nhất vì không cần gán nhãn thủ công.\n",
    "\n",
    "2) **Robustness**: áp dụng vài biến đổi nhẹ (resize/crop/brightness) lên ảnh query → vẫn hit được id.\n",
    "\n",
    "3) **Hiệu năng**: latency p50/p95 cho endpoint ảnh.\n",
    "\n",
    "> Điều kiện: bạn cần ingest ảnh trước (chạy `ingest_images.py` hoặc gọi `POST /ingest_image`). Nếu chưa ingest, endpoint ảnh có thể trả kết quả rỗng hoặc lỗi.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9752c543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMAGE_DIR=datasets\\archive\\fashion-dataset\\images exists=True | cases=20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>image</th>\n",
       "      <th>expected_id</th>\n",
       "      <th>top_k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_10000</td>\n",
       "      <td>datasets\\archive\\fashion-dataset\\images\\10000.jpg</td>\n",
       "      <td>10000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_10001</td>\n",
       "      <td>datasets\\archive\\fashion-dataset\\images\\10001.jpg</td>\n",
       "      <td>10001</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_10002</td>\n",
       "      <td>datasets\\archive\\fashion-dataset\\images\\10002.jpg</td>\n",
       "      <td>10002</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name                                              image expected_id  \\\n",
       "0  img_10000  datasets\\archive\\fashion-dataset\\images\\10000.jpg       10000   \n",
       "1  img_10001  datasets\\archive\\fashion-dataset\\images\\10001.jpg       10001   \n",
       "2  img_10002  datasets\\archive\\fashion-dataset\\images\\10002.jpg       10002   \n",
       "\n",
       "   top_k  \n",
       "0      5  \n",
       "1      5  \n",
       "2      5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# C.1) Utilities gọi endpoint ảnh + tạo testset tự động\n",
    "\n",
    "import io\n",
    "from dataclasses import dataclass\n",
    "\n",
    "try:\n",
    "    from PIL import Image, ImageEnhance\n",
    "except Exception:\n",
    "    Image = None\n",
    "    ImageEnhance = None\n",
    "\n",
    "\n",
    "IMAGE_DIR = Path(os.getenv(\"EVAL_IMAGE_DIR\", \"datasets/archive/fashion-dataset/images\"))\n",
    "IMAGE_TOP_K = int(os.getenv(\"EVAL_IMAGE_TOP_K\", \"5\"))\n",
    "IMAGE_N_SAMPLES = int(os.getenv(\"EVAL_IMAGE_N_SAMPLES\", \"20\"))\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ImageTestCase:\n",
    "    name: str\n",
    "    image_path: Path\n",
    "    expected_id: Optional[str] = None\n",
    "    top_k: int = IMAGE_TOP_K\n",
    "\n",
    "\n",
    "def _list_image_files(img_dir: Path) -> List[Path]:\n",
    "    if not img_dir.exists():\n",
    "        return []\n",
    "    exts = {\".jpg\", \".jpeg\", \".png\"}\n",
    "    files = [p for p in img_dir.glob(\"*\") if p.suffix.lower() in exts]\n",
    "    files.sort(key=lambda p: p.name)\n",
    "    return files\n",
    "\n",
    "\n",
    "def _expected_id_from_filename(p: Path) -> Optional[str]:\n",
    "    # dataset uses <id>.jpg\n",
    "    m = re.match(r\"^(\\d+)\", p.stem)\n",
    "    return m.group(1) if m else None\n",
    "\n",
    "\n",
    "def call_image_search_file(image_path: Path, top_k: int = 5) -> dict:\n",
    "    \"\"\"Call POST /search/image/upload with a local file.\n",
    "\n",
    "    Returns dict with: status, latency_ms, error, response\n",
    "    \"\"\"\n",
    "    url = f\"{API_BASE}/search/image/upload\"\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    try:\n",
    "        with image_path.open(\"rb\") as f:\n",
    "            files = {\"file\": (image_path.name, f, \"application/octet-stream\")}\n",
    "            resp = requests.post(url, files=files, params={\"top_k\": int(top_k)}, timeout=TIMEOUT_S)\n",
    "        latency_ms = (time.perf_counter() - t0) * 1000\n",
    "        try:\n",
    "            data = resp.json()\n",
    "        except Exception:\n",
    "            data = {\"_raw\": resp.text}\n",
    "\n",
    "        err = None\n",
    "        if not (200 <= resp.status_code < 300):\n",
    "            err = f\"HTTP {resp.status_code}: {data}\"\n",
    "\n",
    "        return {\"status\": resp.status_code, \"latency_ms\": latency_ms, \"error\": err, \"response\": data}\n",
    "    except Exception as e:\n",
    "        latency_ms = (time.perf_counter() - t0) * 1000\n",
    "        return {\"status\": 0, \"latency_ms\": latency_ms, \"error\": f\"{type(e).__name__}: {e}\", \"response\": {}}\n",
    "\n",
    "\n",
    "def call_image_search_bytes(image_bytes: bytes, filename: str = \"query.jpg\", top_k: int = 5) -> dict:\n",
    "    \"\"\"Call POST /search/image/upload with bytes (for robustness variants).\"\"\"\n",
    "    url = f\"{API_BASE}/search/image/upload\"\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    try:\n",
    "        bio = io.BytesIO(image_bytes)\n",
    "        files = {\"file\": (filename, bio, \"application/octet-stream\")}\n",
    "        resp = requests.post(url, files=files, params={\"top_k\": int(top_k)}, timeout=TIMEOUT_S)\n",
    "        latency_ms = (time.perf_counter() - t0) * 1000\n",
    "        try:\n",
    "            data = resp.json()\n",
    "        except Exception:\n",
    "            data = {\"_raw\": resp.text}\n",
    "\n",
    "        err = None\n",
    "        if not (200 <= resp.status_code < 300):\n",
    "            err = f\"HTTP {resp.status_code}: {data}\"\n",
    "\n",
    "        return {\"status\": resp.status_code, \"latency_ms\": latency_ms, \"error\": err, \"response\": data}\n",
    "    except Exception as e:\n",
    "        latency_ms = (time.perf_counter() - t0) * 1000\n",
    "        return {\"status\": 0, \"latency_ms\": latency_ms, \"error\": f\"{type(e).__name__}: {e}\", \"response\": {}}\n",
    "\n",
    "\n",
    "def build_image_testset(n_samples: int = 20) -> List[ImageTestCase]:\n",
    "    files = _list_image_files(IMAGE_DIR)\n",
    "    if not files:\n",
    "        return []\n",
    "\n",
    "    # Deterministic sample: first N files (stable across runs)\n",
    "    pick = files[: max(1, min(n_samples, len(files)))]\n",
    "    out = []\n",
    "    for p in pick:\n",
    "        out.append(\n",
    "            ImageTestCase(\n",
    "                name=f\"img_{p.stem}\",\n",
    "                image_path=p,\n",
    "                expected_id=_expected_id_from_filename(p),\n",
    "                top_k=IMAGE_TOP_K,\n",
    "            )\n",
    "        )\n",
    "    return out\n",
    "\n",
    "\n",
    "IMAGE_TESTSET = build_image_testset(IMAGE_N_SAMPLES)\n",
    "print(f\"IMAGE_DIR={IMAGE_DIR} exists={IMAGE_DIR.exists()} | cases={len(IMAGE_TESTSET)}\")\n",
    "if IMAGE_TESTSET[:3]:\n",
    "    display(pd.DataFrame([{\"name\": t.name, \"image\": str(t.image_path), \"expected_id\": t.expected_id, \"top_k\": t.top_k} for t in IMAGE_TESTSET[:3]]))\n",
    "else:\n",
    "    print(\"[HINT] Không tìm thấy ảnh. Hãy kiểm tra EVAL_IMAGE_DIR hoặc dataset path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73ac1337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>variant</th>\n",
       "      <th>image</th>\n",
       "      <th>expected_id</th>\n",
       "      <th>status</th>\n",
       "      <th>latency_ms</th>\n",
       "      <th>error</th>\n",
       "      <th>pred_ids</th>\n",
       "      <th>n_results</th>\n",
       "      <th>hit@1</th>\n",
       "      <th>recall@1</th>\n",
       "      <th>ndcg@1</th>\n",
       "      <th>hit@3</th>\n",
       "      <th>recall@3</th>\n",
       "      <th>ndcg@3</th>\n",
       "      <th>hit@5</th>\n",
       "      <th>recall@5</th>\n",
       "      <th>ndcg@5</th>\n",
       "      <th>mrr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_10000</td>\n",
       "      <td>orig</td>\n",
       "      <td>datasets\\archive\\fashion-dataset\\images\\10000.jpg</td>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>30014.2030</td>\n",
       "      <td>ReadTimeout: HTTPConnectionPool(host='127.0.0....</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_10001</td>\n",
       "      <td>orig</td>\n",
       "      <td>datasets\\archive\\fashion-dataset\\images\\10001.jpg</td>\n",
       "      <td>10001</td>\n",
       "      <td>0</td>\n",
       "      <td>30004.3613</td>\n",
       "      <td>ReadTimeout: HTTPConnectionPool(host='127.0.0....</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_10002</td>\n",
       "      <td>orig</td>\n",
       "      <td>datasets\\archive\\fashion-dataset\\images\\10002.jpg</td>\n",
       "      <td>10002</td>\n",
       "      <td>200</td>\n",
       "      <td>1152.1375</td>\n",
       "      <td>None</td>\n",
       "      <td>[10002, 41000, 41001, 38503, 38938]</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_10003</td>\n",
       "      <td>orig</td>\n",
       "      <td>datasets\\archive\\fashion-dataset\\images\\10003.jpg</td>\n",
       "      <td>10003</td>\n",
       "      <td>200</td>\n",
       "      <td>150.0781</td>\n",
       "      <td>None</td>\n",
       "      <td>[10003, 22627, 22579, 22600, 17923]</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_10004</td>\n",
       "      <td>orig</td>\n",
       "      <td>datasets\\archive\\fashion-dataset\\images\\10004.jpg</td>\n",
       "      <td>10004</td>\n",
       "      <td>200</td>\n",
       "      <td>220.5692</td>\n",
       "      <td>None</td>\n",
       "      <td>[10004, 38566, 32648, 14024, 38568]</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name variant                                              image  \\\n",
       "0  img_10000    orig  datasets\\archive\\fashion-dataset\\images\\10000.jpg   \n",
       "1  img_10001    orig  datasets\\archive\\fashion-dataset\\images\\10001.jpg   \n",
       "2  img_10002    orig  datasets\\archive\\fashion-dataset\\images\\10002.jpg   \n",
       "3  img_10003    orig  datasets\\archive\\fashion-dataset\\images\\10003.jpg   \n",
       "4  img_10004    orig  datasets\\archive\\fashion-dataset\\images\\10004.jpg   \n",
       "\n",
       "  expected_id  status  latency_ms  \\\n",
       "0       10000       0  30014.2030   \n",
       "1       10001       0  30004.3613   \n",
       "2       10002     200   1152.1375   \n",
       "3       10003     200    150.0781   \n",
       "4       10004     200    220.5692   \n",
       "\n",
       "                                               error  \\\n",
       "0  ReadTimeout: HTTPConnectionPool(host='127.0.0....   \n",
       "1  ReadTimeout: HTTPConnectionPool(host='127.0.0....   \n",
       "2                                               None   \n",
       "3                                               None   \n",
       "4                                               None   \n",
       "\n",
       "                              pred_ids  n_results  hit@1  recall@1  ndcg@1  \\\n",
       "0                                   []          0    0.0       0.0     0.0   \n",
       "1                                   []          0    0.0       0.0     0.0   \n",
       "2  [10002, 41000, 41001, 38503, 38938]          5    1.0       1.0     1.0   \n",
       "3  [10003, 22627, 22579, 22600, 17923]          5    1.0       1.0     1.0   \n",
       "4  [10004, 38566, 32648, 14024, 38568]          5    1.0       1.0     1.0   \n",
       "\n",
       "   hit@3  recall@3  ndcg@3  hit@5  recall@5  ndcg@5  mrr  \n",
       "0    0.0       0.0     0.0    0.0       0.0     0.0  0.0  \n",
       "1    0.0       0.0     0.0    0.0       0.0     0.0  0.0  \n",
       "2    1.0       1.0     1.0    1.0       1.0     1.0  1.0  \n",
       "3    1.0       1.0     1.0    1.0       1.0     1.0  1.0  \n",
       "4    1.0       1.0     1.0    1.0       1.0     1.0  1.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# C.2) Robustness variants (tuỳ chọn) + runner\n",
    "\n",
    "\n",
    "def make_variants(image_path: Path) -> Dict[str, bytes]:\n",
    "    \"\"\"Return a dict variant_name -> encoded image bytes.\n",
    "\n",
    "    If PIL is unavailable, returns only original bytes.\n",
    "    \"\"\"\n",
    "    raw = image_path.read_bytes()\n",
    "    variants: Dict[str, bytes] = {\"orig\": raw}\n",
    "\n",
    "    if Image is None:\n",
    "        return variants\n",
    "\n",
    "    try:\n",
    "        img = Image.open(io.BytesIO(raw)).convert(\"RGB\")\n",
    "    except Exception:\n",
    "        return variants\n",
    "\n",
    "    # NOTE: avoid referencing Image.Image in type annotations because this notebook\n",
    "    # intentionally sets Image=None when Pillow isn't installed; that confuses some linters.\n",
    "    def _to_jpeg_bytes(im, quality: int = 90) -> bytes:\n",
    "        b = io.BytesIO()\n",
    "        im.save(b, format=\"JPEG\", quality=quality)\n",
    "        return b.getvalue()\n",
    "\n",
    "    # Resize smaller (simulate thumbnail)\n",
    "    try:\n",
    "        im = img.copy()\n",
    "        im.thumbnail((224, 224))\n",
    "        variants[\"thumb_224\"] = _to_jpeg_bytes(im)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Center crop square\n",
    "    try:\n",
    "        im = img.copy()\n",
    "        w, h = im.size\n",
    "        side = min(w, h)\n",
    "        left = (w - side) // 2\n",
    "        top = (h - side) // 2\n",
    "        im = im.crop((left, top, left + side, top + side)).resize((224, 224))\n",
    "        variants[\"center_crop_224\"] = _to_jpeg_bytes(im)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Brightness up/down\n",
    "    if ImageEnhance is not None:\n",
    "        try:\n",
    "            variants[\"bright_1p2\"] = _to_jpeg_bytes(ImageEnhance.Brightness(img).enhance(1.2))\n",
    "        except Exception:\n",
    "            pass\n",
    "        try:\n",
    "            variants[\"bright_0p8\"] = _to_jpeg_bytes(ImageEnhance.Brightness(img).enhance(0.8))\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # Horizontal flip\n",
    "    try:\n",
    "        variants[\"flip_lr\"] = _to_jpeg_bytes(img.transpose(Image.FLIP_LEFT_RIGHT))\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    return variants\n",
    "\n",
    "\n",
    "def _ids_from_image_results(resp: dict) -> List[str]:\n",
    "    results = (resp or {}).get(\"results\") or []\n",
    "    out: List[str] = []\n",
    "    for r in results:\n",
    "        if isinstance(r, dict) and r.get(\"id\") is not None:\n",
    "            out.append(str(r.get(\"id\")))\n",
    "    return out\n",
    "\n",
    "\n",
    "def run_image_eval(testset: List[ImageTestCase], k_values: List[int] = [1, 3, 5], with_variants: bool = True) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    iterator = tqdm(testset, desc=\"ImageEval\") if tqdm else testset\n",
    "\n",
    "    for tc in iterator:\n",
    "        if not tc.image_path.exists():\n",
    "            rows.append({\"name\": tc.name, \"status\": 0, \"error\": \"missing_file\", \"image\": str(tc.image_path)})\n",
    "            continue\n",
    "\n",
    "        expected = tc.expected_id\n",
    "        gold = [expected] if expected else []\n",
    "\n",
    "        if with_variants:\n",
    "            var_map = make_variants(tc.image_path)\n",
    "        else:\n",
    "            var_map = {\"orig\": tc.image_path.read_bytes()}\n",
    "\n",
    "        for vname, vbytes in var_map.items():\n",
    "            res = call_image_search_bytes(vbytes, filename=f\"{tc.image_path.stem}_{vname}.jpg\", top_k=tc.top_k)\n",
    "            pred_ids = _ids_from_image_results(res.get(\"response\") or {})\n",
    "\n",
    "            row = {\n",
    "                \"name\": tc.name,\n",
    "                \"variant\": vname,\n",
    "                \"image\": str(tc.image_path),\n",
    "                \"expected_id\": expected,\n",
    "                \"status\": res.get(\"status\"),\n",
    "                \"latency_ms\": float(res.get(\"latency_ms\") or 0.0),\n",
    "                \"error\": res.get(\"error\"),\n",
    "                \"pred_ids\": pred_ids,\n",
    "                \"n_results\": len(pred_ids),\n",
    "            }\n",
    "            for k in k_values:\n",
    "                row[f\"hit@{k}\"] = hit_at_k(pred_ids, gold, k) if gold else float(\"nan\")\n",
    "                row[f\"recall@{k}\"] = recall_at_k(pred_ids, gold, k) if gold else float(\"nan\")\n",
    "                row[f\"ndcg@{k}\"] = ndcg_at_k(pred_ids, gold, k) if gold else float(\"nan\")\n",
    "            row[\"mrr\"] = mrr(pred_ids, gold) if gold else float(\"nan\")\n",
    "\n",
    "            rows.append(row)\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "IMG_DF = run_image_eval(IMAGE_TESTSET, with_variants=True)\n",
    "IMG_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3e43675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"n_rows\": 20,\n",
      "  \"n_cases\": 20,\n",
      "  \"error_rate\": 0.1,\n",
      "  \"empty_results_rate\": 0.1,\n",
      "  \"latency_p50_ms\": 150.89359999910812,\n",
      "  \"latency_p90_ms\": 4037.3598800012087,\n",
      "  \"latency_p95_ms\": 30004.85338500148,\n",
      "  \"latency_mean_ms\": 3186.539654999433,\n",
      "  \"hit@1\": 0.9,\n",
      "  \"hit@3\": 0.9,\n",
      "  \"hit@5\": 0.9,\n",
      "  \"mrr\": 0.9,\n",
      "  \"per_variant\": [\n",
      "    {\n",
      "      \"variant\": \"orig\",\n",
      "      \"mrr\": 0.9,\n",
      "      \"hit@1\": 0.9,\n",
      "      \"hit@3\": 0.9,\n",
      "      \"hit@5\": 0.9\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Saved:\n",
      "- D:\\Study\\CS311\\CS311\\outputs\\eval_image_results.csv\n",
      "- D:\\Study\\CS311\\CS311\\artifacts\\image_eval_summary.json\n"
     ]
    }
   ],
   "source": [
    "# C.3) Tổng hợp metrics cho Image RAG + xuất artifacts\n",
    "\n",
    "\n",
    "def summarize_image_eval(img_df: pd.DataFrame, k_values: List[int] = [1, 3, 5]) -> Dict[str, Any]:\n",
    "    if img_df is None or len(img_df) == 0:\n",
    "        return {\"n_rows\": 0}\n",
    "\n",
    "    out: Dict[str, Any] = {\n",
    "        \"n_rows\": int(len(img_df)),\n",
    "        \"n_cases\": int(img_df[\"name\"].nunique()) if \"name\" in img_df.columns else None,\n",
    "        \"error_rate\": float((img_df[\"status\"].fillna(0).astype(int) == 0).mean()) if \"status\" in img_df.columns else None,\n",
    "        \"empty_results_rate\": float((img_df[\"n_results\"].fillna(0).astype(int) == 0).mean()) if \"n_results\" in img_df.columns else None,\n",
    "    }\n",
    "\n",
    "    if \"latency_ms\" in img_df.columns:\n",
    "        lat = img_df[\"latency_ms\"].astype(float)\n",
    "        out.update(\n",
    "            {\n",
    "                \"latency_p50_ms\": float(lat.quantile(0.50)),\n",
    "                \"latency_p90_ms\": float(lat.quantile(0.90)),\n",
    "                \"latency_p95_ms\": float(lat.quantile(0.95)),\n",
    "                \"latency_mean_ms\": float(lat.mean()),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    for k in k_values:\n",
    "        col = f\"hit@{k}\"\n",
    "        if col in img_df.columns:\n",
    "            out[col] = float(img_df[col].mean())\n",
    "\n",
    "    if \"mrr\" in img_df.columns:\n",
    "        out[\"mrr\"] = float(img_df[\"mrr\"].mean())\n",
    "\n",
    "    # Optional: per-variant breakdown\n",
    "    if \"variant\" in img_df.columns:\n",
    "        per_variant = (\n",
    "            img_df.groupby(\"variant\")[[c for c in [\"mrr\"] + [f\"hit@{k}\" for k in k_values] if c in img_df.columns]]\n",
    "            .mean(numeric_only=True)\n",
    "            .reset_index()\n",
    "        )\n",
    "        out[\"per_variant\"] = per_variant.to_dict(orient=\"records\")\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "IMG_SUMMARY = summarize_image_eval(IMG_DF)\n",
    "print(json.dumps(IMG_SUMMARY, ensure_ascii=False, indent=2))\n",
    "\n",
    "img_csv = OUTPUTS_DIR / \"eval_image_results.csv\"\n",
    "IMG_DF.to_csv(img_csv, index=False, encoding=\"utf-8\")\n",
    "(ARTIFACTS_DIR / \"image_eval_summary.json\").write_text(json.dumps(IMG_SUMMARY, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\"-\", img_csv.resolve())\n",
    "print(\"-\", (ARTIFACTS_DIR / \"image_eval_summary.json\").resolve())\n",
    "\n",
    "# Optional plot\n",
    "if plt is not None and len(IMG_DF) and \"latency_ms\" in IMG_DF.columns:\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    plt.hist(IMG_DF[\"latency_ms\"].astype(float), bins=20)\n",
    "    plt.title(\"Image search latency histogram (ms)\")\n",
    "    plt.xlabel(\"ms\")\n",
    "    plt.ylabel(\"count\")\n",
    "    plt.grid(True, alpha=0.2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a662a72b",
   "metadata": {},
   "source": [
    "## Text LLM Evaluation (rubric + optional judge + A/B win-rate)\n",
    "\n",
    "Phần này tập trung đánh giá **chất lượng câu trả lời dạng text**.\n",
    "\n",
    "Vì hệ hiện tại tạo `answer` từ `products` (deterministic), nên đánh giá “tối ưu” cho text là:\n",
    "\n",
    "1) **Rubric scoring (rule-based)**: rẻ, ổn định, chạy được trong CI.\n",
    "2) **LLM-as-a-judge (optional)**: chỉ bật khi bạn cấu hình `LLM_*` để chấm các tiêu chí mềm (usefulness, clarity…).\n",
    "3) **A/B win-rate**: so 2 phiên bản API (A và B) theo tỷ lệ thắng (pairwise comparison).\n",
    "\n",
    "### Khi nào dùng A/B?\n",
    "- Khi bạn thay đổi embedding model, threshold lọc, prompt, hoặc bật LLM generative.\n",
    "- A và B nên là **hai base URL khác nhau** (vd 2 container / 2 nhánh config).\n",
    "\n",
    "> Cấu hình: đặt `API_BASE_A` và `API_BASE_B` trong environment. Nếu không đặt, sẽ dùng `API_BASE` hiện tại.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a89ae46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>rubric_faithfulness</th>\n",
       "      <th>rubric_format</th>\n",
       "      <th>rubric_completeness</th>\n",
       "      <th>rubric_constraint</th>\n",
       "      <th>rubric_conciseness</th>\n",
       "      <th>rubric_total</th>\n",
       "      <th>rubric_pick_count</th>\n",
       "      <th>rubric_answer_chars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>basic_men_shoes_budget</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>formal_office</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>color_strict</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>type_tshirts</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>reject_vietnamese</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     name  rubric_faithfulness  rubric_format  \\\n",
       "0  basic_men_shoes_budget                    2              2   \n",
       "1           formal_office                    0              2   \n",
       "2            color_strict                    2              2   \n",
       "3            type_tshirts                    2              2   \n",
       "4       reject_vietnamese                    2              0   \n",
       "\n",
       "   rubric_completeness  rubric_constraint  rubric_conciseness  rubric_total  \\\n",
       "0                    2                  2                   2            10   \n",
       "1                    2                  2                   2             8   \n",
       "2                    2                  2                   2            10   \n",
       "3                    2                  1                   2             9   \n",
       "4                    0                  2                   2             6   \n",
       "\n",
       "   rubric_pick_count  rubric_answer_chars  \n",
       "0                  4                  594  \n",
       "1                  4                  586  \n",
       "2                  4                  543  \n",
       "3                  4                  561  \n",
       "4                  0                   54  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rule-based rubric avg:\n",
      "rubric_faithfulness      1.6\n",
      "rubric_format            1.6\n",
      "rubric_completeness      1.6\n",
      "rubric_constraint        1.8\n",
      "rubric_conciseness       2.0\n",
      "rubric_total             8.6\n",
      "rubric_pick_count        3.2\n",
      "rubric_answer_chars    467.6\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# T.1) Rule-based rubric scoring\n",
    "\n",
    "# We keep this section dependency-light: only stdlib + pandas.\n",
    "\n",
    "API_BASE_A = os.getenv(\"API_BASE_A\", API_BASE).rstrip(\"/\")\n",
    "API_BASE_B = os.getenv(\"API_BASE_B\", \"\").rstrip(\"/\")\n",
    "\n",
    "\n",
    "def _extract_pick_lines(answer: str) -> List[str]:\n",
    "    \"\"\"Extract lines that look like enumerated picks: '1) ...'\"\"\"\n",
    "    lines = (answer or \"\").splitlines()\n",
    "    picks = []\n",
    "    for ln in lines:\n",
    "        if re.match(r\"^\\s*\\d+\\)\\s+\", ln):\n",
    "            picks.append(ln.strip())\n",
    "    return picks\n",
    "\n",
    "\n",
    "def rubric_score_rule_based(\n",
    "    query: str,\n",
    "    answer: str,\n",
    "    products: list,\n",
    "    expected_constraints: Optional[Dict[str, Any]] = None,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Return rubric scores (0..2) using deterministic rules.\n",
    "\n",
    "    Dimensions (0..2):\n",
    "    - faithfulness: consistent with products (uses existing heuristic)\n",
    "    - format: has a 'Top picks' section with enumerated items\n",
    "    - completeness: mentions 2-4 picks and includes id for each\n",
    "    - constraint_support: if constraints exist, returned products satisfy them\n",
    "    - conciseness: not too long / not empty\n",
    "\n",
    "    Note: for 'constraint_support' we reuse constraint_checks() which checks returned products.\n",
    "    \"\"\"\n",
    "    ans = answer or \"\"\n",
    "\n",
    "    # Faithfulness\n",
    "    faith = faithfulness_heuristic(ans, products)\n",
    "    faithfulness = 2 if faith.get(\"faithful\") else 0\n",
    "\n",
    "    # Format\n",
    "    picks = _extract_pick_lines(ans)\n",
    "    has_top_picks_header = bool(re.search(r\"(?im)^\\s*top\\s+picks\\s*:\\s*$\", ans))\n",
    "    if has_top_picks_header and len(picks) >= 2:\n",
    "        format_score = 2\n",
    "    elif len(picks) >= 1:\n",
    "        format_score = 1\n",
    "    else:\n",
    "        format_score = 0\n",
    "\n",
    "    # Completeness\n",
    "    # We want 2-4 unique ids mentioned as '(123)' OR ' (123)'\n",
    "    mentioned_ids = set(re.findall(r\"\\((\\d+)\\)\", ans))\n",
    "    prod_ids = set(_ids_from_products(products))\n",
    "    mentioned_valid = [x for x in mentioned_ids if x in prod_ids]\n",
    "    if 2 <= len(picks) <= 4 and len(mentioned_valid) >= min(2, len(prod_ids)):\n",
    "        completeness = 2\n",
    "    elif len(picks) >= 1:\n",
    "        completeness = 1\n",
    "    else:\n",
    "        completeness = 0\n",
    "\n",
    "    # Constraint support\n",
    "    c = constraint_checks(products, expected_constraints)\n",
    "    constraint_support = 2 if c.get(\"constraint_pass\") else (1 if c.get(\"has_products\") else 0)\n",
    "\n",
    "    # Conciseness\n",
    "    n_chars = len(ans.strip())\n",
    "    if n_chars == 0:\n",
    "        conciseness = 0\n",
    "    elif n_chars <= 1200:\n",
    "        conciseness = 2\n",
    "    else:\n",
    "        conciseness = 1\n",
    "\n",
    "    total = faithfulness + format_score + completeness + constraint_support + conciseness\n",
    "\n",
    "    return {\n",
    "        \"rubric_faithfulness\": faithfulness,\n",
    "        \"rubric_format\": format_score,\n",
    "        \"rubric_completeness\": completeness,\n",
    "        \"rubric_constraint\": constraint_support,\n",
    "        \"rubric_conciseness\": conciseness,\n",
    "        \"rubric_total\": total,\n",
    "        # helpful debug fields\n",
    "        \"rubric_pick_count\": len(picks),\n",
    "        \"rubric_answer_chars\": n_chars,\n",
    "    }\n",
    "\n",
    "\n",
    "def score_df_rule_based(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for _, r in df.iterrows():\n",
    "        rs = rubric_score_rule_based(\n",
    "            query=r.get(\"query\") or \"\",\n",
    "            answer=r.get(\"answer\") or \"\",\n",
    "            products=r.get(\"products\") or [],\n",
    "            expected_constraints=r.get(\"expected_constraints\"),\n",
    "        )\n",
    "        rows.append({\"name\": r.get(\"name\"), **rs})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "RUBRIC_DF = score_df_rule_based(DF)\n",
    "display(RUBRIC_DF)\n",
    "print(\"Rule-based rubric avg:\")\n",
    "print(RUBRIC_DF[[c for c in RUBRIC_DF.columns if c.startswith('rubric_')]].mean(numeric_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b5b0764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'llm_judge_enabled': True, 'LLM_BASE_URL': 'https://router.huggingface.co/v1', 'LLM_MODEL': 'meta-llama/Llama-3.1-8B-Instruct'}\n"
     ]
    }
   ],
   "source": [
    "# T.2) Optional LLM-as-a-judge (bật khi có LLM_*)\n",
    "\n",
    "# We support OpenAI-compatible endpoints via the `openai` Python package.\n",
    "# The project already depends on `openai` in requirements.txt.\n",
    "\n",
    "LLM_BASE_URL = (os.getenv(\"LLM_BASE_URL\", \"\") or \"\").strip()\n",
    "LLM_API_KEY = (os.getenv(\"LLM_API_KEY\", \"\") or \"\").strip()\n",
    "LLM_MODEL = (os.getenv(\"LLM_MODEL\", \"\") or \"\").strip()\n",
    "\n",
    "\n",
    "def _llm_judge_enabled() -> bool:\n",
    "    return bool(LLM_API_KEY and LLM_MODEL)\n",
    "\n",
    "\n",
    "def _get_openai_client_for_judge():\n",
    "    from openai import OpenAI\n",
    "\n",
    "    base_url = LLM_BASE_URL.strip() or \"https://api.openai.com/v1\"\n",
    "    return OpenAI(base_url=base_url, api_key=LLM_API_KEY)\n",
    "\n",
    "\n",
    "def llm_judge_pairwise(\n",
    "    query: str,\n",
    "    a: Dict[str, Any],\n",
    "    b: Dict[str, Any],\n",
    "    max_tokens: int = 400,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Pairwise judge between system A and B.\n",
    "\n",
    "    Inputs a/b should contain:\n",
    "    - answer: str\n",
    "    - products: list[dict]\n",
    "\n",
    "    Returns dict with winner in {\"A\",\"B\",\"TIE\"} and per-dimension scores.\n",
    "    \"\"\"\n",
    "    if not _llm_judge_enabled():\n",
    "        return {\"enabled\": False, \"winner\": \"TIE\", \"reason\": \"LLM judge disabled (missing LLM_API_KEY/LLM_MODEL)\"}\n",
    "\n",
    "    # Keep products slim to reduce prompt size and avoid leaking irrelevant fields.\n",
    "    def slim_products(ps: list) -> list:\n",
    "        out = []\n",
    "        for p in ps or []:\n",
    "            if not isinstance(p, dict):\n",
    "                continue\n",
    "            out.append(\n",
    "                {\n",
    "                    \"id\": p.get(\"id\"),\n",
    "                    \"name\": p.get(\"name\"),\n",
    "                    \"price\": p.get(\"price\"),\n",
    "                    \"color\": p.get(\"color\"),\n",
    "                    \"gender\": p.get(\"gender\"),\n",
    "                    \"category\": p.get(\"category\"),\n",
    "                    \"subcategory\": p.get(\"subcategory\"),\n",
    "                    \"usage\": p.get(\"usage\"),\n",
    "                }\n",
    "            )\n",
    "        return out\n",
    "\n",
    "    payload = {\n",
    "        \"query\": query,\n",
    "        \"system_A\": {\"answer\": a.get(\"answer\") or \"\", \"products\": slim_products(a.get(\"products\") or [])},\n",
    "        \"system_B\": {\"answer\": b.get(\"answer\") or \"\", \"products\": slim_products(b.get(\"products\") or [])},\n",
    "        \"rubric\": {\n",
    "            \"faithfulness\": \"Answer must not contradict or invent facts not present in its own product list.\",\n",
    "            \"usefulness\": \"Clear, actionable, and matches the shopping intent.\",\n",
    "            \"format\": \"2–4 picks with id + short reason.\",\n",
    "        },\n",
    "    }\n",
    "\n",
    "    prompt = (\n",
    "        \"You are a strict evaluator for a shopping assistant.\\n\"\n",
    "        \"You will compare System A vs System B for the same user query.\\n\"\n",
    "        \"CRITICAL: Each system has its own PRODUCT LIST. Treat each list as authoritative for that system.\\n\"\n",
    "        \"Penalize hallucinations: mentioning prices/colors/ids not in that system's product list.\\n\"\n",
    "        \"Return ONLY valid JSON with this schema:\\n\"\n",
    "        \"{\\n\"\n",
    "        \"  \\\"winner\\\": \\\"A\\\"|\\\"B\\\"|\\\"TIE\\\",\\n\"\n",
    "        \"  \\\"scores\\\": {\\\"A\\\": {\\\"faithfulness\\\":0|1|2,\\\"usefulness\\\":0|1|2,\\\"format\\\":0|1|2},\\n\"\n",
    "        \"             \\\"B\\\": {\\\"faithfulness\\\":0|1|2,\\\"usefulness\\\":0|1|2,\\\"format\\\":0|1|2}},\\n\"\n",
    "        \"  \\\"reason\\\": \\\"short explanation\\\"\\n\"\n",
    "        \"}\\n\\n\"\n",
    "        f\"INPUT:\\n{json.dumps(payload, ensure_ascii=False)}\"\n",
    "    )\n",
    "\n",
    "    client = _get_openai_client_for_judge()\n",
    "    try:\n",
    "        resp = client.chat.completions.create(\n",
    "            model=LLM_MODEL,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0,\n",
    "            max_tokens=max_tokens,\n",
    "        )\n",
    "        txt = (resp.choices[0].message.content or \"\").strip()\n",
    "        # Best-effort parse\n",
    "        data = json.loads(txt)\n",
    "        data[\"enabled\"] = True\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        return {\"enabled\": True, \"winner\": \"TIE\", \"reason\": f\"Judge error: {type(e).__name__}: {e}\"}\n",
    "\n",
    "\n",
    "print({\"llm_judge_enabled\": _llm_judge_enabled(), \"LLM_BASE_URL\": LLM_BASE_URL or \"(default)\", \"LLM_MODEL\": LLM_MODEL or \"(unset)\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a538645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'API_BASE_A': 'http://127.0.0.1:8081', 'API_BASE_B': '(not set)'}\n",
      "A/B is disabled because API_BASE_B is not set.\n",
      "To enable A/B, set environment variables:\n",
      "- API_BASE_A=http://127.0.0.1:8081 (or your A server)\n",
      "- API_BASE_B=http://127.0.0.1:8082 (or your B server)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# T.3) A/B evaluation + win-rate report\n",
    "\n",
    "\n",
    "def call_chat_against_base(api_base: str, query: str, top_k: int = 5, filters: Optional[dict] = None, messages: Optional[list] = None) -> dict:\n",
    "    api_base = (api_base or \"\").rstrip(\"/\")\n",
    "    if not api_base:\n",
    "        return {\"status\": 0, \"latency_ms\": 0.0, \"error\": \"missing api_base\", \"response\": {}}\n",
    "\n",
    "    payload: Dict[str, Any] = {\"query\": query, \"top_k\": int(top_k)}\n",
    "    if filters:\n",
    "        payload[\"filters\"] = filters\n",
    "    if messages:\n",
    "        payload[\"messages\"] = messages\n",
    "\n",
    "    # Reuse _request_json logic, but with explicit base\n",
    "    status, data, latency_ms, err = _request_json(\"POST\", f\"{api_base}/chat\", payload)\n",
    "    return {\"status\": status, \"latency_ms\": latency_ms, \"error\": err, \"response\": data}\n",
    "\n",
    "\n",
    "def run_eval_on_base(api_base: str, testset: List[TestCase]) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    iterator = tqdm(testset, desc=f\"Eval {api_base}\") if tqdm else testset\n",
    "    for tc in iterator:\n",
    "        res = call_chat_against_base(api_base, tc.query, top_k=tc.top_k)\n",
    "        resp = res.get(\"response\") or {}\n",
    "        rows.append(\n",
    "            {\n",
    "                \"name\": tc.name,\n",
    "                \"query\": tc.query,\n",
    "                \"status\": res.get(\"status\"),\n",
    "                \"latency_ms\": float(res.get(\"latency_ms\") or 0.0),\n",
    "                \"error\": res.get(\"error\"),\n",
    "                \"answer\": resp.get(\"answer\"),\n",
    "                \"products\": resp.get(\"products\") or [],\n",
    "                \"sources\": resp.get(\"sources\") or [],\n",
    "                \"expected_constraints\": tc.expected_constraints,\n",
    "            }\n",
    "        )\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def ab_winrate_rule_based(df_a: pd.DataFrame, df_b: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Compare A vs B using rule-based rubric_total.\"\"\"\n",
    "    a_sc = score_df_rule_based(df_a).set_index(\"name\")\n",
    "    b_sc = score_df_rule_based(df_b).set_index(\"name\")\n",
    "\n",
    "    names = sorted(set(a_sc.index) & set(b_sc.index))\n",
    "    rows = []\n",
    "    for n in names:\n",
    "        a = a_sc.loc[n].to_dict()\n",
    "        b = b_sc.loc[n].to_dict()\n",
    "        a_total = float(a.get(\"rubric_total\") or 0)\n",
    "        b_total = float(b.get(\"rubric_total\") or 0)\n",
    "        if a_total > b_total:\n",
    "            winner = \"A\"\n",
    "        elif b_total > a_total:\n",
    "            winner = \"B\"\n",
    "        else:\n",
    "            winner = \"TIE\"\n",
    "        rows.append({\"name\": n, \"winner_rule\": winner, \"A_total\": a_total, \"B_total\": b_total})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def ab_winrate_llm_judge(df_a: pd.DataFrame, df_b: pd.DataFrame, max_cases: int = 30) -> pd.DataFrame:\n",
    "    \"\"\"Compare A vs B using optional LLM judge.\"\"\"\n",
    "    names = sorted(set(df_a[\"name\"]) & set(df_b[\"name\"]))\n",
    "    names = names[: max_cases]\n",
    "\n",
    "    rows = []\n",
    "    for n in (tqdm(names, desc=\"LLM-judge A/B\") if tqdm else names):\n",
    "        ra = df_a[df_a[\"name\"] == n].iloc[0].to_dict()\n",
    "        rb = df_b[df_b[\"name\"] == n].iloc[0].to_dict()\n",
    "\n",
    "        out = llm_judge_pairwise(\n",
    "            query=ra.get(\"query\") or \"\",\n",
    "            a={\"answer\": ra.get(\"answer\"), \"products\": ra.get(\"products\")},\n",
    "            b={\"answer\": rb.get(\"answer\"), \"products\": rb.get(\"products\")},\n",
    "        )\n",
    "\n",
    "        rows.append({\"name\": n, **out})\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def summarize_winrate(win_df: pd.DataFrame, winner_col: str) -> Dict[str, Any]:\n",
    "    if win_df is None or len(win_df) == 0:\n",
    "        return {\"n\": 0}\n",
    "    counts = win_df[winner_col].value_counts(dropna=False).to_dict()\n",
    "    n = int(len(win_df))\n",
    "    return {\n",
    "        \"n\": n,\n",
    "        \"A_wins\": int(counts.get(\"A\", 0)),\n",
    "        \"B_wins\": int(counts.get(\"B\", 0)),\n",
    "        \"ties\": int(counts.get(\"TIE\", 0)),\n",
    "        \"A_win_rate\": float(counts.get(\"A\", 0) / max(1, n)),\n",
    "        \"B_win_rate\": float(counts.get(\"B\", 0) / max(1, n)),\n",
    "    }\n",
    "\n",
    "\n",
    "print({\"API_BASE_A\": API_BASE_A, \"API_BASE_B\": API_BASE_B or \"(not set)\"})\n",
    "\n",
    "# Only run A/B if API_BASE_B is provided\n",
    "if API_BASE_B:\n",
    "    DF_A = run_eval_on_base(API_BASE_A, TESTSET)\n",
    "    DF_B = run_eval_on_base(API_BASE_B, TESTSET)\n",
    "\n",
    "    WIN_RULE = ab_winrate_rule_based(DF_A, DF_B)\n",
    "    print(\"Rule-based win-rate summary:\")\n",
    "    print(json.dumps(summarize_winrate(WIN_RULE, \"winner_rule\"), ensure_ascii=False, indent=2))\n",
    "    display(WIN_RULE)\n",
    "\n",
    "    # Optional LLM judge win-rate\n",
    "    if _llm_judge_enabled():\n",
    "        WIN_JUDGE = ab_winrate_llm_judge(DF_A, DF_B, max_cases=len(TESTSET))\n",
    "        # Normalize winner field if missing\n",
    "        if \"winner\" in WIN_JUDGE.columns:\n",
    "            WIN_JUDGE[\"winner\"] = WIN_JUDGE[\"winner\"].fillna(\"TIE\")\n",
    "        print(\"LLM-judge win-rate summary:\")\n",
    "        print(json.dumps(summarize_winrate(WIN_JUDGE, \"winner\"), ensure_ascii=False, indent=2))\n",
    "        display(WIN_JUDGE[[c for c in [\"name\", \"winner\", \"reason\"] if c in WIN_JUDGE.columns]])\n",
    "\n",
    "        # Save judge artifacts\n",
    "        (ARTIFACTS_DIR / \"ab_llm_judge.jsonl\").write_text(\n",
    "            \"\\n\".join(json.dumps(r, ensure_ascii=False) for r in WIN_JUDGE.to_dict(orient=\"records\")),\n",
    "            encoding=\"utf-8\",\n",
    "        )\n",
    "\n",
    "    # Save A/B artifacts\n",
    "    (ARTIFACTS_DIR / \"ab_rule_winrate.csv\").write_text(WIN_RULE.to_csv(index=False), encoding=\"utf-8\")\n",
    "    DF_A.to_csv(OUTPUTS_DIR / \"eval_text_A.csv\", index=False, encoding=\"utf-8\")\n",
    "    DF_B.to_csv(OUTPUTS_DIR / \"eval_text_B.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "    print(\"Saved A/B artifacts to outputs/ and artifacts/\")\n",
    "else:\n",
    "    print(\n",
    "        \"A/B is disabled because API_BASE_B is not set.\\n\"\n",
    "        \"To enable A/B, set environment variables:\\n\"\n",
    "        \"- API_BASE_A=http://127.0.0.1:8081 (or your A server)\\n\"\n",
    "        \"- API_BASE_B=http://127.0.0.1:8082 (or your B server)\\n\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
